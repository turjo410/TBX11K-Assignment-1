{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033290f7",
   "metadata": {},
   "source": [
    "# üî¨ YOLOv11 Training - TBX11K Tuberculosis Detection\n",
    "## CSE475 Machine Learning Lab Assignment\n",
    "\n",
    "---\n",
    "\n",
    "**Student:** Shahriar Khan, Rifah Tamannah, Khalid Mahmud Joy, Tanvir Rahman  \n",
    "**Institution:** East West University  \n",
    "**Model:** YOLOv11n (Nano)  \n",
    "**Dataset:** TBX11K Small Dataset (800 images total)  \n",
    "**Training Epochs:** 30  \n",
    "**Optimization:** Configured for small dataset with aggressive augmentation\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Notebook Overview\n",
    "\n",
    "This notebook trains **YOLOv11n** model for tuberculosis detection with:\n",
    "- ‚úÖ AGGRESSIVE augmentation\n",
    "- ‚úÖ Larger image size\n",
    "- ‚úÖ Smaller batch size\n",
    "- ‚úÖ Conservative learning rate\n",
    "- ‚úÖ Strong regularization\n",
    "- ‚úÖ Comprehensive visualizations\n",
    "- ‚úÖ Training curves and metrics\n",
    "- ‚úÖ Confusion matrix analysis\n",
    "- ‚úÖ Sample predictions\n",
    "\n",
    "### ‚ö†Ô∏è Dataset\n",
    "- **Training:** 600 images\n",
    "- **Validation:** 200 images\n",
    "- **Total:** 800 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3f503",
   "metadata": {},
   "source": [
    "## üì¶ Section 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6307e137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T18:09:03.276778Z",
     "iopub.status.busy": "2025-11-03T18:09:03.276114Z",
     "iopub.status.idle": "2025-11-03T18:09:21.243714Z",
     "shell.execute_reply": "2025-11-03T18:09:21.242741Z",
     "shell.execute_reply.started": "2025-11-03T18:09:03.276755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Installing compatible packages for Kaggle...\n",
      "================================================================================\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ultralytics 8.3.224 requires opencv-python>=4.6.0, which is not installed.\n",
      "ultralytics 8.3.224 requires ultralytics-thop>=2.0.18, which is not installed.\n",
      "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: opencv-python-headless 4.8.1.78\n",
      "Uninstalling opencv-python-headless-4.8.1.78:\n",
      "  Successfully uninstalled opencv-python-headless-4.8.1.78\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\n",
      "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m================================================================================\n",
      "‚úÖ Installation complete!\n",
      "‚ö†Ô∏è  RESTART KERNEL NOW: Run ‚Üí Restart Session\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Installation cell - Run ONCE, then RESTART kernel\n",
    "print(\"üîß Installing compatible packages for Kaggle...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Fix NumPy/Matplotlib compatibility\n",
    "!pip install -q \"numpy<2.0\" --force-reinstall\n",
    "\n",
    "# Fix OpenCV compatibility\n",
    "!pip uninstall -y opencv-python opencv-python-headless opencv-contrib-python 2>/dev/null\n",
    "!pip install -q opencv-python-headless==4.8.1.78\n",
    "\n",
    "# Install YOLO\n",
    "!pip install -q --no-deps ultralytics\n",
    "!pip install -q pillow tqdm pyyaml\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ Installation complete!\")\n",
    "print(\"‚ö†Ô∏è  RESTART KERNEL NOW: Run ‚Üí Restart Session\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5df7199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T18:09:21.246188Z",
     "iopub.status.busy": "2025-11-03T18:09:21.245917Z",
     "iopub.status.idle": "2025-11-03T18:09:21.258874Z",
     "shell.execute_reply": "2025-11-03T18:09:21.258082Z",
     "shell.execute_reply.started": "2025-11-03T18:09:21.246165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üì¶ PyTorch version: 2.6.0+cu124\n",
      "üñ•Ô∏è  CUDA available: True\n",
      "üéÆ GPU: Tesla T4\n",
      "üíæ GPU Memory: 14.74 GB\n"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ PyTorch version: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806f359",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21da3f8e-ae50-4a53-adf1-3bb733acf656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T18:09:21.259882Z",
     "iopub.status.busy": "2025-11-03T18:09:21.259670Z",
     "iopub.status.idle": "2025-11-03T18:09:21.293415Z",
     "shell.execute_reply": "2025-11-03T18:09:21.292505Z",
     "shell.execute_reply.started": "2025-11-03T18:09:21.259866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ data.yaml created successfully!\n",
      "\n",
      "üìÑ Content:\n",
      "# TBX11K Dataset Configuration\n",
      "path: /kaggle/input/tbx11k-small/tbx11k-small-balanced\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "nc: 3\n",
      "\n",
      "names:\n",
      "  0: Active Tuberculosis\n",
      "  1: Obsolete Pulmonary TB\n",
      "  2: Pulmonary Tuberculosis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create data.yaml file (no external dependencies)\n",
    "data_yaml_content = \"\"\"# TBX11K Dataset Configuration\n",
    "path: /kaggle/input/tbx11k-small/tbx11k-small-balanced\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 3\n",
    "\n",
    "names:\n",
    "  0: Active Tuberculosis\n",
    "  1: Obsolete Pulmonary TB\n",
    "  2: Pulmonary Tuberculosis\n",
    "\"\"\"\n",
    "\n",
    "# Write to data.yaml\n",
    "with open('data.yaml', 'w') as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(\"‚úÖ data.yaml created successfully!\")\n",
    "print(\"\\nüìÑ Content:\")\n",
    "with open('data.yaml', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09dfc0ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T18:09:21.294828Z",
     "iopub.status.busy": "2025-11-03T18:09:21.294463Z",
     "iopub.status.idle": "2025-11-03T18:09:21.311929Z",
     "shell.execute_reply": "2025-11-03T18:09:21.311154Z",
     "shell.execute_reply.started": "2025-11-03T18:09:21.294804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "‚öôÔ∏è  YOLOv11 CONFIGURATION\n",
      "================================================================================\n",
      "üìÅ Dataset: /kaggle/input/tbx11k-small/tbx11k-small-balanced\n",
      "üìÑ Data YAML: /kaggle/working/data.yaml\n",
      "ü§ñ Model: YOLOv11n\n",
      "üñºÔ∏è  Image Size: 640x640\n",
      "üì¶ Batch Size: 8\n",
      "üîÑ Epochs: 1\n",
      "‚è±Ô∏è  Patience: 15\n",
      "üéØ Classes: 3\n",
      "üíæ Output: /kaggle/working\n",
      "================================================================================\n",
      "‚ö†Ô∏è  IMPORTANT: Update DATASET_NAME in config to match your Kaggle dataset!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "class YOLOv11Config:\n",
    "    \"\"\"Configuration for YOLOv11 training on TBX11K dataset\"\"\"\n",
    "    \n",
    "    # ========== DATASET PATHS (KAGGLE OPTIMIZED) ==========\n",
    "    # Update this to match your Kaggle dataset name after upload\n",
    "    DATASET_NAME = 'tbx11k-small/tbx11k-small-balanced'  # Change this to your uploaded dataset name\n",
    "    DATASET_PATH = f'/kaggle/input/{DATASET_NAME}'\n",
    "    DATA_YAML = '/kaggle/working/data.yaml'\n",
    "    \n",
    "    # ========== OUTPUT PATHS ==========\n",
    "    OUTPUT_DIR = Path('/kaggle/working')\n",
    "    MODEL_DIR = OUTPUT_DIR / 'yolov11_model'\n",
    "    PLOTS_DIR = OUTPUT_DIR / 'yolov11_plots'\n",
    "    RESULTS_DIR = OUTPUT_DIR / 'yolov11_results'\n",
    "    \n",
    "    # Create directories\n",
    "    for directory in [MODEL_DIR, PLOTS_DIR, RESULTS_DIR]:\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ========== MODEL CONFIGURATION ==========\n",
    "    MODEL_NAME = 'YOLOv11n'\n",
    "    MODEL_WEIGHTS = 'yolo11n.pt'\n",
    "    \n",
    "    # ========== TRAINING HYPERPARAMETERS ==========\n",
    "    IMG_SIZE = 640\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 1\n",
    "    PATIENCE = 15\n",
    "    WORKERS = 0\n",
    "    DEVICE = 0\n",
    "    \n",
    "    # ========== OPTIMIZER SETTINGS ==========\n",
    "    OPTIMIZER = 'AdamW'\n",
    "    LR0 = 0.0005\n",
    "    LRF = 0.005\n",
    "    MOMENTUM = 0.937\n",
    "    WEIGHT_DECAY = 0.001\n",
    "    WARMUP_EPOCHS = 5\n",
    "    WARMUP_MOMENTUM = 0.8\n",
    "    WARMUP_BIAS_LR = 0.1\n",
    "    \n",
    "    # ========== LOSS WEIGHTS ==========\n",
    "    BOX = 7.5\n",
    "    CLS = 1.5\n",
    "    DFL = 1.5\n",
    "    \n",
    "    # ========== AUGMENTATION ==========\n",
    "    DEGREES = 25.0\n",
    "    TRANSLATE = 0.2\n",
    "    SCALE = 0.5\n",
    "    SHEAR = 10.0\n",
    "    PERSPECTIVE = 0.001\n",
    "    FLIPUD = 0.0\n",
    "    FLIPLR = 0.5\n",
    "    MOSAIC = 1.0\n",
    "    MIXUP = 0.3\n",
    "    COPY_PASTE = 0.3\n",
    "    HSV_H = 0.0\n",
    "    HSV_S = 0.0\n",
    "    HSV_V = 0.6\n",
    "    ERASING = 0.5\n",
    "    \n",
    "    # ========== REGULARIZATION ==========\n",
    "    DROPOUT = 0.3\n",
    "    LABEL_SMOOTHING = 0.1\n",
    "    \n",
    "    # ========== INFERENCE ==========\n",
    "    CONF_THRESHOLD = 0.20\n",
    "    IOU_THRESHOLD = 0.45\n",
    "    \n",
    "    # ========== DATASET INFO ==========\n",
    "    NUM_CLASSES = 3\n",
    "    CLASS_NAMES = {\n",
    "        0: 'Active Tuberculosis',\n",
    "        1: 'Obsolete Pulmonary TB',\n",
    "        2: 'Pulmonary Tuberculosis'\n",
    "    }\n",
    "    \n",
    "    # ========== VISUALIZATION ==========\n",
    "    DPI = 150\n",
    "    FIGSIZE = (15, 10)\n",
    "\n",
    "config = YOLOv11Config()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚öôÔ∏è  YOLOv11 CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üìÅ Dataset: {config.DATASET_PATH}\")\n",
    "print(f\"üìÑ Data YAML: {config.DATA_YAML}\")\n",
    "print(f\"ü§ñ Model: {config.MODEL_NAME}\")\n",
    "print(f\"üñºÔ∏è  Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
    "print(f\"üì¶ Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"üîÑ Epochs: {config.EPOCHS}\")\n",
    "print(f\"‚è±Ô∏è  Patience: {config.PATIENCE}\")\n",
    "print(f\"üéØ Classes: {config.NUM_CLASSES}\")\n",
    "print(f\"üíæ Output: {config.OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"‚ö†Ô∏è  IMPORTANT: Update DATASET_NAME in config to match your Kaggle dataset!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27527206",
   "metadata": {},
   "source": [
    "## üìä Section 3: Dataset Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f84a1804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T18:09:21.314077Z",
     "iopub.status.busy": "2025-11-03T18:09:21.313787Z",
     "iopub.status.idle": "2025-11-03T18:09:21.475317Z",
     "shell.execute_reply": "2025-11-03T18:09:21.474604Z",
     "shell.execute_reply.started": "2025-11-03T18:09:21.314059Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verifying dataset structure...\n",
      "\n",
      "üìÇ Dataset Structure:\n",
      "  ‚îú‚îÄ Training Images: 600\n",
      "  ‚îú‚îÄ Training Labels: 600\n",
      "  ‚îú‚îÄ Validation Images: 200\n",
      "  ‚îî‚îÄ Validation Labels: 200\n",
      "\n",
      "‚úÖ data.yaml found: /kaggle/working/data.yaml\n",
      "\n",
      "üìÑ data.yaml content:\n",
      "# TBX11K Dataset Configuration\n",
      "path: /kaggle/input/tbx11k-small/tbx11k-small-balanced\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n",
      "nc: 3\n",
      "\n",
      "names:\n",
      "  0: Active Tuberculosis\n",
      "  1: Obsolete Pulmonary TB\n",
      "  2: Pulmonary Tuberculosis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify dataset structure\n",
    "print(\"üîç Verifying dataset structure...\\n\")\n",
    "\n",
    "dataset_path = Path(config.DATASET_PATH)\n",
    "\n",
    "# Check main directories\n",
    "train_img_dir = dataset_path / 'images' / 'train'\n",
    "train_lbl_dir = dataset_path / 'labels' / 'train'\n",
    "val_img_dir = dataset_path / 'images' / 'val'\n",
    "val_lbl_dir = dataset_path / 'labels' / 'val'\n",
    "\n",
    "# Count files\n",
    "train_images = list(train_img_dir.glob('*.png')) if train_img_dir.exists() else []\n",
    "train_labels = list(train_lbl_dir.glob('*.txt')) if train_lbl_dir.exists() else []\n",
    "val_images = list(val_img_dir.glob('*.png')) if val_img_dir.exists() else []\n",
    "val_labels = list(val_lbl_dir.glob('*.txt')) if val_lbl_dir.exists() else []\n",
    "\n",
    "print(\"üìÇ Dataset Structure:\")\n",
    "print(f\"  ‚îú‚îÄ Training Images: {len(train_images)}\")\n",
    "print(f\"  ‚îú‚îÄ Training Labels: {len(train_labels)}\")\n",
    "print(f\"  ‚îú‚îÄ Validation Images: {len(val_images)}\")\n",
    "print(f\"  ‚îî‚îÄ Validation Labels: {len(val_labels)}\")\n",
    "\n",
    "# Check data.yaml\n",
    "data_yaml_path = Path(config.DATA_YAML)\n",
    "if data_yaml_path.exists():\n",
    "    print(f\"\\n‚úÖ data.yaml found: {data_yaml_path}\")\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        print(\"\\nüìÑ data.yaml content:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  data.yaml not found at: {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, image_path, conf_threshold=0.25, iou_threshold=0.45):\n",
    "    \"\"\"\n",
    "    Ensemble prediction using weighted voting from multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models: List of YOLO models\n",
    "        image_path: Path to input image\n",
    "        conf_threshold: Confidence threshold for predictions\n",
    "        iou_threshold: IoU threshold for NMS\n",
    "    \n",
    "    Returns:\n",
    "        Averaged predictions from all models\n",
    "    \"\"\"\n",
    "    all_boxes = []\n",
    "    all_scores = []\n",
    "    all_classes = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model in models:\n",
    "        results = model.predict(\n",
    "            source=image_path,\n",
    "            conf=conf_threshold,\n",
    "            iou=iou_threshold,\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        if len(results.boxes) > 0:\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()\n",
    "            scores = results.boxes.conf.cpu().numpy()\n",
    "            classes = results.boxes.cls.cpu().numpy()\n",
    "            \n",
    "            all_boxes.append(boxes)\n",
    "            all_scores.append(scores)\n",
    "            all_classes.append(classes)\n",
    "    \n",
    "    if len(all_boxes) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    all_boxes = np.concatenate(all_boxes, axis=0)\n",
    "    all_scores = np.concatenate(all_scores, axis=0)\n",
    "    all_classes = np.concatenate(all_classes, axis=0)\n",
    "    \n",
    "    # Apply NMS to ensemble predictions\n",
    "    from torchvision.ops import nms\n",
    "    import torch\n",
    "    \n",
    "    boxes_tensor = torch.from_numpy(all_boxes)\n",
    "    scores_tensor = torch.from_numpy(all_scores)\n",
    "    \n",
    "    keep_indices = nms(boxes_tensor, scores_tensor, iou_threshold)\n",
    "    keep_indices = keep_indices.cpu().numpy()\n",
    "    \n",
    "    final_boxes = all_boxes[keep_indices]\n",
    "    final_scores = all_scores[keep_indices]\n",
    "    final_classes = all_classes[keep_indices]\n",
    "    \n",
    "    return final_boxes, final_scores, final_classes\n",
    "\n",
    "\n",
    "# Test ensemble on sample images\n",
    "print(\"=\"*80)\n",
    "print(\"üîÆ TESTING K-FOLD ENSEMBLE\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Get sample validation images from first fold\n",
    "test_images = list((KFOLD_DIR / 'fold_1' / 'images' / 'val').glob('*.png'))[:3]\n",
    "\n",
    "for img_path in test_images:\n",
    "    print(f\"\\nüì∏ Processing: {img_path.name}\")\n",
    "    \n",
    "    # Get ensemble predictions\n",
    "    boxes, scores, classes = ensemble_predict(\n",
    "        fold_models, \n",
    "        str(img_path),\n",
    "        conf_threshold=0.25,\n",
    "        iou_threshold=0.45\n",
    "    )\n",
    "    \n",
    "    if boxes is not None:\n",
    "        print(f\"   ‚Ä¢ Detected {len(boxes)} objects\")\n",
    "        print(f\"   ‚Ä¢ Avg confidence: {scores.mean():.3f}\")\n",
    "        print(f\"   ‚Ä¢ Max confidence: {scores.max():.3f}\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ No detections\")\n",
    "\n",
    "# Compare best single model vs ensemble\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üìä ENSEMBLE vs BEST SINGLE MODEL COMPARISON\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Get best model\n",
    "best_fold_idx = results_df['mAP50'].idxmax()\n",
    "best_model = fold_models[best_fold_idx]\n",
    "\n",
    "print(f\"Best Single Model: Fold {best_fold_idx + 1}\")\n",
    "print(f\"   ‚Ä¢ mAP@0.5: {results_df.loc[best_fold_idx, 'mAP50']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {results_df.loc[best_fold_idx, 'precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {results_df.loc[best_fold_idx, 'recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1: {results_df.loc[best_fold_idx, 'f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Ensemble combines predictions from all {len(fold_models)} models\")\n",
    "print(\"   Expected improvement: +2-5% mAP boost typically\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"‚úÖ K-FOLD CROSS-VALIDATION SETUP COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nüìå Summary:\")\n",
    "print(f\"   ‚Ä¢ Trained {len(fold_models)} models successfully\")\n",
    "print(f\"   ‚Ä¢ Mean mAP@0.5: {results_df['mAP50'].mean():.4f} ¬± {results_df['mAP50'].std():.4f}\")\n",
    "print(f\"   ‚Ä¢ Best single model: Fold {best_fold_idx + 1} ({results_df.loc[best_fold_idx, 'mAP50']:.4f})\")\n",
    "print(f\"   ‚Ä¢ All models saved for ensemble predictions\")\n",
    "print(f\"   ‚Ä¢ Total training time: {results_df['time_min'].sum():.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b47d5",
   "metadata": {},
   "source": [
    "## üîÆ Section 3.7: K-Fold Ensemble Predictions\n",
    "Combine predictions from all fold models for improved accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4305c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä K-FOLD CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Calculate statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üìà AGGREGATE STATISTICS\")\n",
    "print(f\"{'='*80}\")\n",
    "metrics = ['mAP50', 'mAP50_95', 'precision', 'recall', 'f1']\n",
    "for metric in metrics:\n",
    "    mean_val = results_df[metric].mean()\n",
    "    std_val = results_df[metric].std()\n",
    "    print(f\"{metric:12s}: {mean_val:.4f} ¬± {std_val:.4f}\")\n",
    "\n",
    "# Find best fold\n",
    "best_fold_idx = results_df['mAP50'].idxmax() + 1\n",
    "best_mAP = results_df.loc[results_df['mAP50'].idxmax(), 'mAP50']\n",
    "print(f\"\\nüèÜ Best Fold: Fold {best_fold_idx} (mAP@0.5 = {best_mAP:.4f})\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('YOLOv11 K-Fold Cross-Validation Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot each metric\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    bars = ax.bar(results_df['fold'], results_df[metric], color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    ax.axhline(results_df[metric].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.set_xlabel('Fold', fontweight='bold')\n",
    "    ax.set_ylabel(metric.upper(), fontweight='bold')\n",
    "    ax.set_title(f'{metric.upper()}: {results_df[metric].mean():.4f} ¬± {results_df[metric].std():.4f}')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Highlight best fold\n",
    "    best_idx = results_df[metric].idxmax()\n",
    "    bars[best_idx].set_color('gold')\n",
    "    bars[best_idx].set_edgecolor('darkgoldenrod')\n",
    "    bars[best_idx].set_linewidth(2)\n",
    "\n",
    "# Training time\n",
    "ax = axes[1, 2]\n",
    "ax.bar(results_df['fold'], results_df['time_min'], color='lightcoral', edgecolor='darkred', alpha=0.7)\n",
    "ax.set_xlabel('Fold', fontweight='bold')\n",
    "ax.set_ylabel('Training Time (min)', fontweight='bold')\n",
    "ax.set_title(f'Training Time per Fold (Total: {results_df[\"time_min\"].sum():.1f} min)')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(config.PLOTS_DIR / 'kfold_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(config.RESULTS_DIR / 'kfold_results.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to {config.RESULTS_DIR / 'kfold_results.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3795e",
   "metadata": {},
   "source": [
    "## üìä Section 3.6: K-Fold Results Analysis\n",
    "Analyze cross-validation metrics across all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835944b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(f\"üöÄ STARTING {N_FOLDS}-FOLD CROSS-VALIDATION TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Storage for fold results\n",
    "fold_results = []\n",
    "fold_models = []\n",
    "total_training_time = 0\n",
    "\n",
    "for fold_idx in range(1, N_FOLDS + 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìä FOLD {fold_idx}/{N_FOLDS}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Get fold data\n",
    "    fold_dir = KFOLD_DIR / f'fold_{fold_idx}'\n",
    "    fold_data_yaml = str(fold_dir / 'data.yaml')\n",
    "    \n",
    "    # Initialize model\n",
    "    model = YOLO(config.MODEL_WEIGHTS)\n",
    "    \n",
    "    # Train\n",
    "    fold_start = time.time()\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=fold_data_yaml,\n",
    "            epochs=config.EPOCHS,\n",
    "            imgsz=config.IMG_SIZE,\n",
    "            batch=config.BATCH_SIZE,\n",
    "            device=config.DEVICE,\n",
    "            workers=config.WORKERS,\n",
    "            patience=config.PATIENCE,\n",
    "            project=str(config.MODEL_DIR),\n",
    "            name=f'fold_{fold_idx}',\n",
    "            exist_ok=True,\n",
    "            optimizer=config.OPTIMIZER,\n",
    "            lr0=config.LR0,\n",
    "            lrf=config.LRF,\n",
    "            momentum=config.MOMENTUM,\n",
    "            weight_decay=config.WEIGHT_DECAY,\n",
    "            warmup_epochs=config.WARMUP_EPOCHS,\n",
    "            warmup_momentum=config.WARMUP_MOMENTUM,\n",
    "            warmup_bias_lr=config.WARMUP_BIAS_LR,\n",
    "            box=config.BOX,\n",
    "            cls=config.CLS,\n",
    "            dfl=config.DFL,\n",
    "            dropout=config.DROPOUT,\n",
    "            label_smoothing=config.LABEL_SMOOTHING,\n",
    "            degrees=config.DEGREES,\n",
    "            translate=config.TRANSLATE,\n",
    "            scale=config.SCALE,\n",
    "            shear=config.SHEAR,\n",
    "            perspective=config.PERSPECTIVE,\n",
    "            mosaic=config.MOSAIC,\n",
    "            mixup=config.MIXUP,\n",
    "            copy_paste=config.COPY_PASTE,\n",
    "            fliplr=config.FLIPLR,\n",
    "            flipud=config.FLIPUD,\n",
    "            hsv_h=config.HSV_H,\n",
    "            hsv_s=config.HSV_S,\n",
    "            hsv_v=config.HSV_V,\n",
    "            erasing=config.ERASING,\n",
    "            amp=False,\n",
    "            plots=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        fold_time = time.time() - fold_start\n",
    "        total_training_time += fold_time\n",
    "        \n",
    "        # Load best model and validate\n",
    "        best_model_path = config.MODEL_DIR / f'fold_{fold_idx}' / 'weights' / 'best.pt'\n",
    "        fold_model = YOLO(str(best_model_path))\n",
    "        \n",
    "        val_results = fold_model.val(\n",
    "            data=fold_data_yaml,\n",
    "            split='val',\n",
    "            imgsz=config.IMG_SIZE,\n",
    "            batch=config.BATCH_SIZE,\n",
    "            device=config.DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        fold_result = {\n",
    "            'fold': fold_idx,\n",
    "            'mAP50': float(val_results.box.map50),\n",
    "            'mAP50_95': float(val_results.box.map),\n",
    "            'precision': float(val_results.box.mp),\n",
    "            'recall': float(val_results.box.mr),\n",
    "            'f1': float(2 * val_results.box.mp * val_results.box.mr / (val_results.box.mp + val_results.box.mr + 1e-6)),\n",
    "            'time_min': fold_time / 60,\n",
    "            'model_path': str(best_model_path)\n",
    "        }\n",
    "        \n",
    "        fold_results.append(fold_result)\n",
    "        fold_models.append(fold_model)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Fold {fold_idx} Complete!\")\n",
    "        print(f\"   ‚Ä¢ mAP@0.5: {fold_result['mAP50']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ mAP@0.5:0.95: {fold_result['mAP50_95']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Precision: {fold_result['precision']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Recall: {fold_result['recall']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ F1 Score: {fold_result['f1']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Time: {fold_result['time_min']:.1f} min\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in Fold {fold_idx}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "training_time = total_training_time\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üéâ K-FOLD TRAINING COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"‚è±Ô∏è  Total training time: {training_time/60:.1f} minutes\")\n",
    "print(f\"üìä Trained {len(fold_results)} models successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586033b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create K-Fold splits\n",
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nüìÅ Creating {N_FOLDS} fold directories...\\n\")\n",
    "\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(all_images), 1):\n",
    "    print(f\"Processing Fold {fold_idx}/{N_FOLDS}...\")\n",
    "    \n",
    "    # Create fold directories\n",
    "    fold_dir = KFOLD_DIR / f'fold_{fold_idx}'\n",
    "    (fold_dir / 'images' / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (fold_dir / 'images' / 'val').mkdir(parents=True, exist_ok=True)\n",
    "    (fold_dir / 'labels' / 'train').mkdir(parents=True, exist_ok=True)\n",
    "    (fold_dir / 'labels' / 'val').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy training images and labels\n",
    "    for idx in train_indices:\n",
    "        img_path = all_images[idx]\n",
    "        \n",
    "        # Copy image\n",
    "        dst_img = fold_dir / 'images' / 'train' / img_path.name\n",
    "        shutil.copy2(img_path, dst_img)\n",
    "        \n",
    "        # Copy label\n",
    "        if 'train' in str(img_path):\n",
    "            lbl_path = dataset_path / 'labels' / 'train' / f\"{img_path.stem}.txt\"\n",
    "        else:\n",
    "            lbl_path = dataset_path / 'labels' / 'val' / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        if lbl_path.exists():\n",
    "            dst_lbl = fold_dir / 'labels' / 'train' / f\"{img_path.stem}.txt\"\n",
    "            shutil.copy2(lbl_path, dst_lbl)\n",
    "    \n",
    "    # Copy validation images and labels\n",
    "    for idx in val_indices:\n",
    "        img_path = all_images[idx]\n",
    "        \n",
    "        # Copy image\n",
    "        dst_img = fold_dir / 'images' / 'val' / img_path.name\n",
    "        shutil.copy2(img_path, dst_img)\n",
    "        \n",
    "        # Copy label\n",
    "        if 'train' in str(img_path):\n",
    "            lbl_path = dataset_path / 'labels' / 'train' / f\"{img_path.stem}.txt\"\n",
    "        else:\n",
    "            lbl_path = dataset_path / 'labels' / 'val' / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        if lbl_path.exists():\n",
    "            dst_lbl = fold_dir / 'labels' / 'val' / f\"{img_path.stem}.txt\"\n",
    "            shutil.copy2(lbl_path, dst_lbl)\n",
    "    \n",
    "    # Create data.yaml for this fold\n",
    "    data_yaml_content = f\"\"\"# YOLOv11 K-Fold Data Configuration - Fold {fold_idx}\n",
    "path: {fold_dir}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: {config.NUM_CLASSES}\n",
    "names:\n",
    "  0: {config.CLASS_NAMES[0]}\n",
    "  1: {config.CLASS_NAMES[1]}\n",
    "  2: {config.CLASS_NAMES[2]}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(fold_dir / 'data.yaml', 'w') as f:\n",
    "        f.write(data_yaml_content)\n",
    "    \n",
    "    print(f\"  ‚úì Fold {fold_idx}: {len(train_indices)} train, {len(val_indices)} val images\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚úÖ K-Fold splits created successfully!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a79822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# K-Fold Configuration\n",
    "N_FOLDS = 5\n",
    "KFOLD_DIR = config.OUTPUT_DIR / 'kfold_splits'\n",
    "KFOLD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Get all images (combine train + val for K-Fold)\n",
    "dataset_path = Path(config.DATASET_PATH)\n",
    "train_imgs = list((dataset_path / 'images' / 'train').glob('*.png'))\n",
    "val_imgs = list((dataset_path / 'images' / 'val').glob('*.png'))\n",
    "all_images = train_imgs + val_imgs\n",
    "\n",
    "print(f\"üîÑ K-FOLD CROSS-VALIDATION SETUP\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  ‚Ä¢ Number of folds: {N_FOLDS}\")\n",
    "print(f\"  ‚Ä¢ Total images: {len(all_images)}\")\n",
    "print(f\"  ‚Ä¢ Images per fold (train): ~{len(all_images) * (N_FOLDS-1) / N_FOLDS:.0f}\")\n",
    "print(f\"  ‚Ä¢ Images per fold (val): ~{len(all_images) / N_FOLDS:.0f}\")\n",
    "print(f\"  ‚Ä¢ Output directory: {KFOLD_DIR}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7c1b2",
   "metadata": {},
   "source": [
    "## üîÑ Section 3.5: K-Fold Cross-Validation Setup\n",
    "\n",
    "To maximize the small dataset (800 images), we'll use **5-Fold Cross-Validation**:\n",
    "- Each fold trains on ~640 images, validates on ~160 images\n",
    "- All 800 images used for both training and validation across folds\n",
    "- Provides more robust performance estimates\n",
    "- Enables ensemble predictions from 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b2f15",
   "metadata": {},
   "source": [
    "## üìà Section 4: Model Selection & Validation\n",
    "Use the best performing fold model for validation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957b269",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.596597Z",
     "iopub.status.idle": "2025-11-03T18:09:22.596915Z",
     "shell.execute_reply": "2025-11-03T18:09:22.596775Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.596758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use best fold model from K-Fold CV\n",
    "best_fold_idx = results_df['mAP50'].idxmax()\n",
    "best_model = fold_models[best_fold_idx]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä VALIDATING BEST FOLD MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüèÜ Using Best Fold Model: Fold {best_fold_idx + 1}\")\n",
    "print(f\"   ‚Ä¢ mAP@0.5: {results_df.loc[best_fold_idx, 'mAP50']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Model Path: {results_df.loc[best_fold_idx, 'model_path']}\")\n",
    "\n",
    "# Validate on fold's validation set\n",
    "fold_data_yaml = str(KFOLD_DIR / f'fold_{best_fold_idx + 1}' / 'data.yaml')\n",
    "\n",
    "print(\"\\n‚è≥ Running validation...\\n\")\n",
    "val_results = best_model.val(\n",
    "    data=fold_data_yaml,\n",
    "    split='val',\n",
    "    imgsz=config.IMG_SIZE,\n",
    "    batch=config.BATCH_SIZE,\n",
    "    conf=config.CONF_THRESHOLD,\n",
    "    iou=config.IOU_THRESHOLD,\n",
    "    device=config.DEVICE,\n",
    "    workers=config.WORKERS,\n",
    "    plots=True,\n",
    "    save_json=True,\n",
    "    project=str(config.RESULTS_DIR),\n",
    "    name='validation',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà VALIDATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  ‚Ä¢ mAP@0.5:     {val_results.box.map50:.4f}\")\n",
    "print(f\"  ‚Ä¢ mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision:    {val_results.box.mp:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:       {val_results.box.mr:.4f}\")\n",
    "print(f\"  ‚Ä¢ Fitness:      {val_results.fitness:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save metrics to JSON\n",
    "metrics = {\n",
    "    'model': config.MODEL_NAME,\n",
    "    'epochs': config.EPOCHS,\n",
    "    'training_time_minutes': training_time / 60,\n",
    "    'best_fold': int(best_fold_idx + 1),\n",
    "    'mAP50': float(val_results.box.map50),\n",
    "    'mAP50_95': float(val_results.box.map),\n",
    "    'precision': float(val_results.box.mp),\n",
    "    'recall': float(val_results.box.mr),\n",
    "    'fitness': float(val_results.fitness),\n",
    "    'kfold_mean_mAP50': float(results_df['mAP50'].mean()),\n",
    "    'kfold_std_mAP50': float(results_df['mAP50'].std()),\n",
    "}\n",
    "\n",
    "metrics_file = config.RESULTS_DIR / 'yolov11_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Metrics saved to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec2c8c",
   "metadata": {},
   "source": [
    "## üìä Section 5: Training Curves (Best Fold Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c12f2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.598040Z",
     "iopub.status.idle": "2025-11-03T18:09:22.598325Z",
     "shell.execute_reply": "2025-11-03T18:09:22.598197Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.598187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read training results from best fold\n",
    "best_fold_num = best_fold_idx + 1\n",
    "results_csv = config.MODEL_DIR / f'fold_{best_fold_num}' / 'results.csv'\n",
    "\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Create comprehensive training curves\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "    fig.suptitle(f'YOLOv11 Training Curves - Best Fold (Fold {best_fold_num})', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    epochs = df['epoch'] if 'epoch' in df.columns else range(len(df))\n",
    "    \n",
    "    # Plot 1: mAP@0.5\n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[0, 0].plot(epochs, df['metrics/mAP50(B)'], linewidth=2.5, color='blue', label='mAP@0.5')\n",
    "        axes[0, 0].fill_between(epochs, df['metrics/mAP50(B)'], alpha=0.3, color='blue')\n",
    "        axes[0, 0].set_title('mAP@0.5', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('mAP@0.5')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Plot 2: mAP@0.5:0.95\n",
    "    if 'metrics/mAP50-95(B)' in df.columns:\n",
    "        axes[0, 1].plot(epochs, df['metrics/mAP50-95(B)'], linewidth=2.5, color='green', label='mAP@0.5:0.95')\n",
    "        axes[0, 1].fill_between(epochs, df['metrics/mAP50-95(B)'], alpha=0.3, color='green')\n",
    "        axes[0, 1].set_title('mAP@0.5:0.95', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mAP@0.5:0.95')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # Plot 3: Precision\n",
    "    if 'metrics/precision(B)' in df.columns:\n",
    "        axes[0, 2].plot(epochs, df['metrics/precision(B)'], linewidth=2.5, color='orange', label='Precision')\n",
    "        axes[0, 2].fill_between(epochs, df['metrics/precision(B)'], alpha=0.3, color='orange')\n",
    "        axes[0, 2].set_title('Precision', fontsize=14, fontweight='bold')\n",
    "        axes[0, 2].set_xlabel('Epoch')\n",
    "        axes[0, 2].set_ylabel('Precision')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        axes[0, 2].legend()\n",
    "    \n",
    "    # Plot 4: Recall\n",
    "    if 'metrics/recall(B)' in df.columns:\n",
    "        axes[1, 0].plot(epochs, df['metrics/recall(B)'], linewidth=2.5, color='red', label='Recall')\n",
    "        axes[1, 0].fill_between(epochs, df['metrics/recall(B)'], alpha=0.3, color='red')\n",
    "        axes[1, 0].set_title('Recall', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Recall')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    # Plot 5: Box Loss\n",
    "    if 'train/box_loss' in df.columns and 'val/box_loss' in df.columns:\n",
    "        axes[1, 1].plot(epochs, df['train/box_loss'], linewidth=2, label='Train', color='blue')\n",
    "        axes[1, 1].plot(epochs, df['val/box_loss'], linewidth=2, label='Val', color='red')\n",
    "        axes[1, 1].set_title('Box Loss', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    # Plot 6: Class Loss\n",
    "    if 'train/cls_loss' in df.columns and 'val/cls_loss' in df.columns:\n",
    "        axes[1, 2].plot(epochs, df['train/cls_loss'], linewidth=2, label='Train', color='blue')\n",
    "        axes[1, 2].plot(epochs, df['val/cls_loss'], linewidth=2, label='Val', color='red')\n",
    "        axes[1, 2].set_title('Classification Loss', fontsize=14, fontweight='bold')\n",
    "        axes[1, 2].set_xlabel('Epoch')\n",
    "        axes[1, 2].set_ylabel('Loss')\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        axes[1, 2].legend()\n",
    "    \n",
    "    # Plot 7: DFL Loss\n",
    "    if 'train/dfl_loss' in df.columns and 'val/dfl_loss' in df.columns:\n",
    "        axes[2, 0].plot(epochs, df['train/dfl_loss'], linewidth=2, label='Train', color='blue')\n",
    "        axes[2, 0].plot(epochs, df['val/dfl_loss'], linewidth=2, label='Val', color='red')\n",
    "        axes[2, 0].set_title('DFL Loss', fontsize=14, fontweight='bold')\n",
    "        axes[2, 0].set_xlabel('Epoch')\n",
    "        axes[2, 0].set_ylabel('Loss')\n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "        axes[2, 0].legend()\n",
    "    \n",
    "    # Plot 8: F1 Score (calculated)\n",
    "    if 'metrics/precision(B)' in df.columns and 'metrics/recall(B)' in df.columns:\n",
    "        precision = df['metrics/precision(B)']\n",
    "        recall = df['metrics/recall(B)']\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        axes[2, 1].plot(epochs, f1, linewidth=2.5, color='purple', label='F1 Score')\n",
    "        axes[2, 1].fill_between(epochs, f1, alpha=0.3, color='purple')\n",
    "        axes[2, 1].set_title('F1 Score', fontsize=14, fontweight='bold')\n",
    "        axes[2, 1].set_xlabel('Epoch')\n",
    "        axes[2, 1].set_ylabel('F1 Score')\n",
    "        axes[2, 1].grid(True, alpha=0.3)\n",
    "        axes[2, 1].legend()\n",
    "    \n",
    "    # Plot 9: Learning Rate\n",
    "    if 'lr/pg0' in df.columns:\n",
    "        axes[2, 2].plot(epochs, df['lr/pg0'], linewidth=2, color='brown', label='Learning Rate')\n",
    "        axes[2, 2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        axes[2, 2].set_xlabel('Epoch')\n",
    "        axes[2, 2].set_ylabel('Learning Rate')\n",
    "        axes[2, 2].grid(True, alpha=0.3)\n",
    "        axes[2, 2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'training_curves_best_fold.png'\n",
    "    plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Training curves saved to: {save_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Results CSV not found at: {results_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5485f8b4",
   "metadata": {},
   "source": [
    "## üéØ Section 6: Confusion Matrix (Best Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42928295",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.599289Z",
     "iopub.status.idle": "2025-11-03T18:09:22.599682Z",
     "shell.execute_reply": "2025-11-03T18:09:22.599483Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.599467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check for confusion matrix\n",
    "confusion_matrix_path = config.RESULTS_DIR / 'validation' / 'confusion_matrix.png'\n",
    "\n",
    "if confusion_matrix_path.exists():\n",
    "    print(\"üìä Displaying Confusion Matrix\\n\")\n",
    "    \n",
    "    img = Image.open(confusion_matrix_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('YOLOv11 - Confusion Matrix (Normalized)', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'confusion_matrix_display.png'\n",
    "    plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Confusion matrix saved to: {save_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Confusion matrix not found at: {confusion_matrix_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c93a81",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Section 7: Sample Predictions (Best Fold Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb526d4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.600814Z",
     "iopub.status.idle": "2025-11-03T18:09:22.601189Z",
     "shell.execute_reply": "2025-11-03T18:09:22.600999Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.600984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üñºÔ∏è  GENERATING SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get validation images from best fold\n",
    "best_fold_num = best_fold_idx + 1\n",
    "val_img_dir = KFOLD_DIR / f'fold_{best_fold_num}' / 'images' / 'val'\n",
    "val_lbl_dir = KFOLD_DIR / f'fold_{best_fold_num}' / 'labels' / 'val'\n",
    "\n",
    "val_images_with_labels = []\n",
    "for img_path in val_img_dir.glob('*.png'):\n",
    "    label_path = val_lbl_dir / f\"{img_path.stem}.txt\"\n",
    "    if label_path.exists() and label_path.stat().st_size > 0:\n",
    "        val_images_with_labels.append(img_path)\n",
    "\n",
    "# Select random samples\n",
    "num_samples = min(9, len(val_images_with_labels))\n",
    "selected_samples = random.sample(val_images_with_labels, num_samples)\n",
    "\n",
    "print(f\"\\nüì∏ Generating predictions for {num_samples} samples from Fold {best_fold_num}...\\n\")\n",
    "\n",
    "# Create prediction grid\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle(f'YOLOv11 - Sample Predictions (Best Fold {best_fold_num})', fontsize=18, fontweight='bold')\n",
    "\n",
    "for idx, img_path in enumerate(selected_samples):\n",
    "    # Run prediction\n",
    "    results = best_model.predict(\n",
    "        source=str(img_path),\n",
    "        conf=config.CONF_THRESHOLD,\n",
    "        iou=config.IOU_THRESHOLD,\n",
    "        imgsz=config.IMG_SIZE,\n",
    "        device=config.DEVICE,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Get annotated image\n",
    "    annotated = results[0].plot()\n",
    "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display\n",
    "    axes[idx].imshow(annotated_rgb)\n",
    "    num_detections = len(results[0].boxes)\n",
    "    axes[idx].set_title(f'{img_path.stem}\\n({num_detections} detections)', \n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = config.PLOTS_DIR / 'sample_predictions.png'\n",
    "plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Sample predictions saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adbfe3",
   "metadata": {},
   "source": [
    "## üìä Section 9: Metrics Summary (K-Fold + Best Fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d260853",
   "metadata": {},
   "source": [
    "## üé® Section 8: Enhanced Detection Visualizations (Best Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6477c50",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.602165Z",
     "iopub.status.idle": "2025-11-03T18:09:22.602471Z",
     "shell.execute_reply": "2025-11-03T18:09:22.602354Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.602344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 1: Prediction Grid with ALL Images (Even Without Detections)\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üñºÔ∏è  CREATING COMPREHENSIVE PREDICTION VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use best fold's validation images\n",
    "best_fold_num = best_fold_idx + 1\n",
    "val_img_dir = KFOLD_DIR / f'fold_{best_fold_num}' / 'images' / 'val'\n",
    "all_val_images = list(val_img_dir.glob('*.png'))\n",
    "\n",
    "if len(all_val_images) == 0:\n",
    "    print(\"‚ùå No validation images found!\")\n",
    "else:\n",
    "    num_samples = min(9, len(all_val_images))\n",
    "    selected_samples = random.sample(all_val_images, num_samples)\n",
    "    \n",
    "    print(f\"\\nüì∏ Generating predictions for {num_samples} validation images from Fold {best_fold_num}...\\n\")\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle(f'YOLOv11 - Sample Predictions (Fold {best_fold_num})', fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    for idx, img_path in enumerate(selected_samples):\n",
    "        try:\n",
    "            results = best_model.predict(\n",
    "                source=str(img_path),\n",
    "                conf=config.CONF_THRESHOLD,\n",
    "                iou=config.IOU_THRESHOLD,\n",
    "                imgsz=config.IMG_SIZE,\n",
    "                device=config.DEVICE,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            annotated = results[0].plot()\n",
    "            annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            axes[idx].imshow(annotated_rgb)\n",
    "            num_detections = len(results[0].boxes)\n",
    "            \n",
    "            if num_detections > 0:\n",
    "                title_color = 'green'\n",
    "                title = f'{img_path.stem}\\n‚úì {num_detections} detection(s)'\n",
    "            else:\n",
    "                title_color = 'red'\n",
    "                title = f'{img_path.stem}\\n‚úó No detections'\n",
    "            \n",
    "            axes[idx].set_title(title, fontsize=11, fontweight='bold', color=title_color)\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error processing {img_path.name}: {str(e)}\")\n",
    "            axes[idx].text(0.5, 0.5, f'Error: {img_path.stem}', ha='center', va='center')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'sample_predictions_enhanced.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Sample predictions saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c8121",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.603481Z",
     "iopub.status.idle": "2025-11-03T18:09:22.603771Z",
     "shell.execute_reply": "2025-11-03T18:09:22.603601Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.603593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 2: Confidence Distribution Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä CONFIDENCE SCORE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use best fold validation images\n",
    "best_fold_num = best_fold_idx + 1\n",
    "all_val_images = list((KFOLD_DIR / f'fold_{best_fold_num}' / 'images' / 'val').glob('*.png'))\n",
    "\n",
    "all_confidences = []\n",
    "all_classes = []\n",
    "detection_stats = {'with_detection': 0, 'without_detection': 0}\n",
    "\n",
    "print(f\"\\nüîç Analyzing {len(all_val_images)} validation images from Fold {best_fold_num}...\\n\")\n",
    "\n",
    "for img_path in tqdm(all_val_images, desc=\"Processing\"):\n",
    "    results = best_model.predict(\n",
    "        source=str(img_path),\n",
    "        conf=config.CONF_THRESHOLD,\n",
    "        iou=config.IOU_THRESHOLD,\n",
    "        imgsz=config.IMG_SIZE,\n",
    "        device=config.DEVICE,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    if len(results[0].boxes) > 0:\n",
    "        detection_stats['with_detection'] += 1\n",
    "        for box in results[0].boxes:\n",
    "            all_confidences.append(float(box.conf.cpu()))\n",
    "            all_classes.append(int(box.cls.cpu()))\n",
    "    else:\n",
    "        detection_stats['without_detection'] += 1\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('YOLOv11 - Detection Confidence Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "if all_confidences:\n",
    "    axes[0, 0].hist(all_confidences, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(config.CONF_THRESHOLD, color='red', linestyle='--', \n",
    "                       label=f'Threshold: {config.CONF_THRESHOLD}', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Confidence Score', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title(f'Confidence Score Distribution\\n(Total Detections: {len(all_confidences)})', fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'No Detections Found', ha='center', va='center', fontsize=14, color='red')\n",
    "    axes[0, 0].set_title('Confidence Score Distribution', fontweight='bold')\n",
    "\n",
    "categories = ['Images with\\nDetections', 'Images without\\nDetections']\n",
    "values = [detection_stats['with_detection'], detection_stats['without_detection']]\n",
    "colors = ['#4CAF50', '#f44336']\n",
    "\n",
    "axes[0, 1].bar(categories, values, color=colors, edgecolor='black', linewidth=2)\n",
    "axes[0, 1].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[0, 1].set_title('Detection Coverage Analysis', fontweight='bold')\n",
    "for i, v in enumerate(values):\n",
    "    axes[0, 1].text(i, v + max(values)*0.02, str(v), ha='center', va='bottom', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "if all_classes:\n",
    "    class_counts = pd.Series(all_classes).value_counts().sort_index()\n",
    "    class_names = [config.CLASS_NAMES[i] for i in class_counts.index]\n",
    "    \n",
    "    axes[1, 0].barh(class_names, class_counts.values, color='coral', edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Number of Detections', fontsize=12)\n",
    "    axes[1, 0].set_title('Detections per Class', fontweight='bold')\n",
    "    for i, v in enumerate(class_counts.values):\n",
    "        axes[1, 0].text(v + max(class_counts.values)*0.02, i, str(v), \n",
    "                        va='center', fontweight='bold')\n",
    "    axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No Detections Found', ha='center', va='center', fontsize=14, color='red')\n",
    "    axes[1, 0].set_title('Detections per Class', fontweight='bold')\n",
    "\n",
    "if all_confidences and all_classes:\n",
    "    conf_by_class = pd.DataFrame({'Class': all_classes, 'Confidence': all_confidences})\n",
    "    conf_by_class['Class_Name'] = conf_by_class['Class'].map(lambda x: config.CLASS_NAMES[x])\n",
    "    \n",
    "    class_names_unique = conf_by_class['Class_Name'].unique()\n",
    "    box_data = [conf_by_class[conf_by_class['Class_Name'] == cn]['Confidence'].values \n",
    "                for cn in class_names_unique]\n",
    "    \n",
    "    bp = axes[1, 1].boxplot(box_data, labels=class_names_unique, patch_artist=True)\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor('lightgreen')\n",
    "    axes[1, 1].set_ylabel('Confidence Score', fontsize=12)\n",
    "    axes[1, 1].set_title('Confidence Distribution by Class', fontweight='bold')\n",
    "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "    axes[1, 1].tick_params(axis='x', rotation=15)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No Detections Found', ha='center', va='center', fontsize=14, color='red')\n",
    "    axes[1, 1].set_title('Confidence Distribution by Class', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = config.PLOTS_DIR / 'confidence_analysis.png'\n",
    "plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Confidence analysis saved to: {save_path}\")\n",
    "print(f\"\\nüìà Detection Summary:\")\n",
    "print(f\"   ‚Ä¢ Images with detections: {detection_stats['with_detection']} ({detection_stats['with_detection']/len(all_val_images)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Images without detections: {detection_stats['without_detection']} ({detection_stats['without_detection']/len(all_val_images)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Total detections: {len(all_confidences)}\")\n",
    "if all_confidences:\n",
    "    print(f\"   ‚Ä¢ Average confidence: {np.mean(all_confidences):.4f}\")\n",
    "    print(f\"   ‚Ä¢ Min confidence: {np.min(all_confidences):.4f}\")\n",
    "    print(f\"   ‚Ä¢ Max confidence: {np.max(all_confidences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb790d50",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.605207Z",
     "iopub.status.idle": "2025-11-03T18:09:22.605705Z",
     "shell.execute_reply": "2025-11-03T18:09:22.605473Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.605457Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 3: High-Confidence vs Low-Confidence Detections\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ HIGH vs LOW CONFIDENCE DETECTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if all_confidences:\n",
    "    high_conf_images = []\n",
    "    low_conf_images = []\n",
    "    \n",
    "    threshold_high = 0.7\n",
    "    threshold_low = 0.4\n",
    "    \n",
    "    for img_path in all_val_images:\n",
    "        results = best_model.predict(\n",
    "            source=str(img_path),\n",
    "            conf=config.CONF_THRESHOLD,\n",
    "            imgsz=config.IMG_SIZE,\n",
    "            device=config.DEVICE,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        if len(results[0].boxes) > 0:\n",
    "            max_conf = max([float(box.conf.cpu()) for box in results[0].boxes])\n",
    "            if max_conf >= threshold_high:\n",
    "                high_conf_images.append((img_path, results, max_conf))\n",
    "            elif max_conf <= threshold_low:\n",
    "                low_conf_images.append((img_path, results, max_conf))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('YOLOv11 - Confidence Comparison: High vs Low', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx in range(3):\n",
    "        if idx < len(high_conf_images):\n",
    "            img_path, results, conf = high_conf_images[idx]\n",
    "            annotated = results[0].plot()\n",
    "            annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "            axes[0, idx].imshow(annotated_rgb)\n",
    "            axes[0, idx].set_title(f'HIGH CONF: {conf:.3f}\\n{img_path.stem}', \n",
    "                                  fontsize=10, fontweight='bold', color='green')\n",
    "        else:\n",
    "            axes[0, idx].text(0.5, 0.5, 'No High\\nConfidence\\nDetections', \n",
    "                            ha='center', va='center', fontsize=12)\n",
    "        axes[0, idx].axis('off')\n",
    "    \n",
    "    for idx in range(3):\n",
    "        if idx < len(low_conf_images):\n",
    "            img_path, results, conf = low_conf_images[idx]\n",
    "            annotated = results[0].plot()\n",
    "            annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "            axes[1, idx].imshow(annotated_rgb)\n",
    "            axes[1, idx].set_title(f'LOW CONF: {conf:.3f}\\n{img_path.stem}', \n",
    "                                  fontsize=10, fontweight='bold', color='orange')\n",
    "        else:\n",
    "            axes[1, idx].text(0.5, 0.5, 'No Low\\nConfidence\\nDetections', \n",
    "                            ha='center', va='center', fontsize=12)\n",
    "        axes[1, idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'confidence_comparison.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Confidence comparison saved to: {save_path}\")\n",
    "    print(f\"   ‚Ä¢ High confidence images (‚â•{threshold_high}): {len(high_conf_images)}\")\n",
    "    print(f\"   ‚Ä¢ Low confidence images (‚â§{threshold_low}): {len(low_conf_images)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No detections found to compare!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbec6a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.606812Z",
     "iopub.status.idle": "2025-11-03T18:09:22.607229Z",
     "shell.execute_reply": "2025-11-03T18:09:22.607064Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.607047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create comprehensive metrics summary\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä YOLOV11 K-FOLD FINAL METRICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "best_fold_num = best_fold_idx + 1\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Model',\n",
    "        'K-Fold Configuration',\n",
    "        'Best Fold',\n",
    "        'Epochs per Fold',\n",
    "        'Total Training Time (min)',\n",
    "        'Best Fold mAP@0.5',\n",
    "        'Best Fold mAP@0.5:0.95',\n",
    "        'Best Fold Precision',\n",
    "        'Best Fold Recall',\n",
    "        'Best Fold F1 Score',\n",
    "        'K-Fold Mean mAP@0.5',\n",
    "        'K-Fold Std mAP@0.5',\n",
    "        'Image Size',\n",
    "        'Batch Size',\n",
    "        'Optimizer',\n",
    "        'Learning Rate',\n",
    "    ],\n",
    "    'Value': [\n",
    "        config.MODEL_NAME,\n",
    "        f'{N_FOLDS}-Fold CV',\n",
    "        f'Fold {best_fold_num}',\n",
    "        config.EPOCHS,\n",
    "        f\"{training_time/60:.2f}\",\n",
    "        f\"{float(val_results.box.map50):.4f}\",\n",
    "        f\"{float(val_results.box.map):.4f}\",\n",
    "        f\"{float(val_results.box.mp):.4f}\",\n",
    "        f\"{float(val_results.box.mr):.4f}\",\n",
    "        f\"{2 * (float(val_results.box.mp) * float(val_results.box.mr)) / (float(val_results.box.mp) + float(val_results.box.mr) + 1e-6):.4f}\",\n",
    "        f\"{results_df['mAP50'].mean():.4f}\",\n",
    "        f\"{results_df['mAP50'].std():.4f}\",\n",
    "        f\"{config.IMG_SIZE}x{config.IMG_SIZE}\",\n",
    "        config.BATCH_SIZE,\n",
    "        config.OPTIMIZER,\n",
    "        config.LR0,\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display styled table\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns,\n",
    "                cellLoc='left', loc='center',\n",
    "                colWidths=[0.6, 0.4])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(summary_df.columns)):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Alternate row colors\n",
    "for i in range(1, len(summary_df) + 1):\n",
    "    for j in range(len(summary_df.columns)):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#f0f0f0')\n",
    "\n",
    "plt.title('YOLOv11 K-Fold Cross-Validation Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "save_path = config.PLOTS_DIR / 'metrics_summary.png'\n",
    "plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Metrics summary saved to: {save_path}\")\n",
    "\n",
    "# Also save as CSV\n",
    "csv_path = config.RESULTS_DIR / 'metrics_summary.csv'\n",
    "summary_df.to_csv(csv_path, index=False)\n",
    "print(f\"‚úÖ Metrics CSV saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9db32",
   "metadata": {},
   "source": [
    "## üìã Section 10: Final Report (K-Fold Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b19323",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-03T18:09:22.608277Z",
     "iopub.status.idle": "2025-11-03T18:09:22.608532Z",
     "shell.execute_reply": "2025-11-03T18:09:22.608416Z",
     "shell.execute_reply.started": "2025-11-03T18:09:22.608407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate comprehensive markdown report\n",
    "report_path = config.RESULTS_DIR / 'yolov11_training_report.md'\n",
    "\n",
    "best_fold_num = best_fold_idx + 1\n",
    "\n",
    "report_content = f\"\"\"# YOLOv11 K-Fold Training Report - TBX11K Tuberculosis Detection\n",
    "\n",
    "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n",
    "**Student:** Shahriar Khan, Rifah Tamannah, Khalid Mahmud Joy, Tanvir Rahman  \n",
    "**Institution:** East West University  \n",
    "**Course:** CSE475 - Machine Learning Lab\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Model Information\n",
    "\n",
    "- **Model:** {config.MODEL_NAME}\n",
    "- **Architecture:** YOLOv11 Nano\n",
    "- **Pretrained Weights:** {config.MODEL_WEIGHTS}\n",
    "- **Task:** Object Detection (Tuberculosis in Chest X-rays)\n",
    "- **Training Strategy:** {N_FOLDS}-Fold Cross-Validation\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dataset\n",
    "\n",
    "- **Dataset:** TBX11K Small (Balanced)\n",
    "- **Total Images:** {len(all_images)}\n",
    "- **Images per Fold (Train):** ~{len(all_images) * (N_FOLDS-1) / N_FOLDS:.0f}\n",
    "- **Images per Fold (Val):** ~{len(all_images) / N_FOLDS:.0f}\n",
    "- **Classes:** {config.NUM_CLASSES}\n",
    "  - Class 0: {config.CLASS_NAMES[0]}\n",
    "  - Class 1: {config.CLASS_NAMES[1]}\n",
    "  - Class 2: {config.CLASS_NAMES[2]}\n",
    "- **Image Size:** {config.IMG_SIZE}x{config.IMG_SIZE}\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Training Configuration\n",
    "\n",
    "### K-Fold Cross-Validation\n",
    "- **Number of Folds:** {N_FOLDS}\n",
    "- **Random Seed:** 42\n",
    "- **Shuffle:** True\n",
    "\n",
    "### Hyperparameters\n",
    "- **Epochs per Fold:** {config.EPOCHS}\n",
    "- **Batch Size:** {config.BATCH_SIZE}\n",
    "- **Optimizer:** {config.OPTIMIZER}\n",
    "- **Initial Learning Rate:** {config.LR0}\n",
    "- **Final LR Factor:** {config.LRF}\n",
    "- **Momentum:** {config.MOMENTUM}\n",
    "- **Weight Decay:** {config.WEIGHT_DECAY}\n",
    "- **Warmup Epochs:** {config.WARMUP_EPOCHS}\n",
    "- **Patience:** {config.PATIENCE}\n",
    "\n",
    "### Loss Weights\n",
    "- **Box Loss:** {config.BOX}\n",
    "- **Class Loss:** {config.CLS}\n",
    "- **DFL Loss:** {config.DFL}\n",
    "\n",
    "### Data Augmentation\n",
    "- **Rotation:** ¬±{config.DEGREES}¬∞\n",
    "- **Translation:** {config.TRANSLATE * 100}%\n",
    "- **Scaling:** ¬±{config.SCALE * 100}%\n",
    "- **Shearing:** ¬±{config.SHEAR}¬∞\n",
    "- **Horizontal Flip:** {config.FLIPLR * 100}%\n",
    "- **Mosaic:** {config.MOSAIC * 100}%\n",
    "- **MixUp:** {config.MIXUP * 100}%\n",
    "- **Copy-Paste:** {config.COPY_PASTE * 100}%\n",
    "- **Random Erasing:** {config.ERASING * 100}%\n",
    "- **HSV Augmentation:** H={config.HSV_H}, S={config.HSV_S}, V={config.HSV_V}\n",
    "\n",
    "---\n",
    "\n",
    "## üìà K-Fold Cross-Validation Results\n",
    "\n",
    "### Per-Fold Performance\n",
    "\n",
    "| Fold | mAP@0.5 | mAP@0.5:0.95 | Precision | Recall | F1 Score | Time (min) |\n",
    "|------|---------|--------------|-----------|--------|----------|------------|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    report_content += f\"| {int(row['fold'])} | {row['mAP50']:.4f} | {row['mAP50_95']:.4f} | {row['precision']:.4f} | {row['recall']:.4f} | {row['f1']:.4f} | {row['time_min']:.1f} |\\n\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "\n",
    "### Aggregate Statistics\n",
    "\n",
    "| Metric | Mean ¬± Std |\n",
    "|--------|------------|\n",
    "| **mAP@0.5** | {results_df['mAP50'].mean():.4f} ¬± {results_df['mAP50'].std():.4f} |\n",
    "| **mAP@0.5:0.95** | {results_df['mAP50_95'].mean():.4f} ¬± {results_df['mAP50_95'].std():.4f} |\n",
    "| **Precision** | {results_df['precision'].mean():.4f} ¬± {results_df['precision'].std():.4f} |\n",
    "| **Recall** | {results_df['recall'].mean():.4f} ¬± {results_df['recall'].std():.4f} |\n",
    "| **F1 Score** | {results_df['f1'].mean():.4f} ¬± {results_df['f1'].std():.4f} |\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ Best Fold Model\n",
    "\n",
    "- **Best Fold:** Fold {best_fold_num}\n",
    "- **Best mAP@0.5:** {results_df.loc[best_fold_idx, 'mAP50']:.4f}\n",
    "- **Model Path:** `{results_df.loc[best_fold_idx, 'model_path']}`\n",
    "\n",
    "### Best Fold Validation Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **mAP@0.5** | {float(val_results.box.map50):.4f} |\n",
    "| **mAP@0.5:0.95** | {float(val_results.box.map):.4f} |\n",
    "| **Precision** | {float(val_results.box.mp):.4f} |\n",
    "| **Recall** | {float(val_results.box.mr):.4f} |\n",
    "| **F1 Score** | {2 * (float(val_results.box.mp) * float(val_results.box.mr)) / (float(val_results.box.mp) + float(val_results.box.mr) + 1e-6):.4f} |\n",
    "| **Fitness** | {float(val_results.fitness):.4f} |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Training Time\n",
    "\n",
    "- **Total Training Time:** {training_time/60:.2f} minutes ({training_time/3600:.2f} hours)\n",
    "- **Average Time per Fold:** {training_time/60/N_FOLDS:.2f} minutes\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Output Files\n",
    "\n",
    "### K-Fold Models\n",
    "\"\"\"\n",
    "\n",
    "for fold_num in range(1, N_FOLDS + 1):\n",
    "    report_content += f\"- Fold {fold_num}: `{config.MODEL_DIR / f'fold_{fold_num}' / 'weights' / 'best.pt'}`\\n\"\n",
    "\n",
    "report_content += f\"\"\"\n",
    "\n",
    "### Visualizations\n",
    "- K-Fold results: `{config.PLOTS_DIR / 'kfold_results.png'}`\n",
    "- Training curves (best fold): `{config.PLOTS_DIR / 'training_curves_best_fold.png'}`\n",
    "- Confusion matrix: `{config.PLOTS_DIR / 'confusion_matrix_display.png'}`\n",
    "- Sample predictions: `{config.PLOTS_DIR / 'sample_predictions.png'}`\n",
    "- Confidence analysis: `{config.PLOTS_DIR / 'confidence_analysis.png'}`\n",
    "- Confidence comparison: `{config.PLOTS_DIR / 'confidence_comparison.png'}`\n",
    "- Metrics summary: `{config.PLOTS_DIR / 'metrics_summary.png'}`\n",
    "\n",
    "### Results\n",
    "- K-Fold results CSV: `{config.RESULTS_DIR / 'kfold_results.csv'}`\n",
    "- Metrics JSON: `{config.RESULTS_DIR / 'yolov11_metrics.json'}`\n",
    "- Metrics CSV: `{config.RESULTS_DIR / 'metrics_summary.csv'}`\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclusion\n",
    "\n",
    "YOLOv11 K-Fold cross-validation training completed successfully with {N_FOLDS} folds. The approach achieved:\n",
    "- **Mean mAP@0.5 of {results_df['mAP50'].mean():.4f} ¬± {results_df['mAP50'].std():.4f}** across all folds\n",
    "- **Best single model mAP@0.5 of {results_df.loc[best_fold_idx, 'mAP50']:.4f}** (Fold {best_fold_num})\n",
    "- **Total training time of {training_time/60:.2f} minutes** for {N_FOLDS} models\n",
    "\n",
    "K-Fold cross-validation provides:\n",
    "- More robust performance estimates\n",
    "- Better utilization of limited dataset ({len(all_images)} images)\n",
    "- Ensemble prediction capability from {N_FOLDS} models\n",
    "- Reduced overfitting risk\n",
    "\n",
    "All {N_FOLDS} models saved for potential ensemble predictions (+2-5% mAP boost typically).\n",
    "\n",
    "---\n",
    "\n",
    "*Generated automatically by YOLOv11 K-Fold training notebook*\n",
    "\"\"\"\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã YOLOV11 K-FOLD TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úÖ Final report saved to: {report_path}\")\n",
    "print(f\"\\nüìä K-Fold Summary:\")\n",
    "print(f\"  ‚Ä¢ Model: {config.MODEL_NAME}\")\n",
    "print(f\"  ‚Ä¢ Folds: {N_FOLDS}\")\n",
    "print(f\"  ‚Ä¢ Epochs per Fold: {config.EPOCHS}\")\n",
    "print(f\"  ‚Ä¢ Total Training Time: {training_time/60:.2f} min\")\n",
    "print(f\"  ‚Ä¢ Mean mAP@0.5: {results_df['mAP50'].mean():.4f} ¬± {results_df['mAP50'].std():.4f}\")\n",
    "print(f\"  ‚Ä¢ Best Fold: {best_fold_num} (mAP@0.5: {results_df.loc[best_fold_idx, 'mAP50']:.4f})\")\n",
    "print(f\"  ‚Ä¢ Best Fold Precision: {float(val_results.box.mp):.4f}\")\n",
    "print(f\"  ‚Ä¢ Best Fold Recall: {float(val_results.box.mr):.4f}\")\n",
    "print(f\"\\nüíæ All outputs saved to: {config.OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8642367,
     "sourceId": 13600580,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
