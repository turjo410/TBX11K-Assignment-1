{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95890eec",
   "metadata": {},
   "source": [
    "# üî¨ YOLOv10 Training - TBX11K Tuberculosis Detection \n",
    "## CSE475 Machine Learning Lab Assignment\n",
    "\n",
    "---\n",
    "\n",
    "**Student:** Shahriar Khan , Rifah Tamannah , Khalid Mahmud Joy , Tanvir Rahman\n",
    "**Institution:** East West University  \n",
    "**Model:** YOLOv10n (Nano)  \n",
    "**Dataset:** TBX11K Small Dataset (800 images total)  \n",
    "**Training Epochs:** 30  \n",
    "**Optimization:** Configured for small dataset with aggressive augmentation\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Notebook Overview\n",
    "\n",
    "This notebook trains **YOLOv10n** model for tuberculosis detection with :\n",
    "- ‚úÖ AGGRESSIVE augmentation \n",
    "- ‚úÖ Larger image size \n",
    "- ‚úÖ Smaller batch size \n",
    "- ‚úÖ Conservative learning rate \n",
    "- ‚úÖ Strong regularization\n",
    "- ‚úÖ Comprehensive visualizations\n",
    "- ‚úÖ Training curves and metrics\n",
    "- ‚úÖ Confusion matrix analysis\n",
    "- ‚úÖ Sample predictions\n",
    "\n",
    "### ‚ö†Ô∏è Dataset \n",
    "- **Training:** 600 images \n",
    "- **Validation:** 200 images\n",
    "- **Total:** 800 images \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb44f4",
   "metadata": {},
   "source": [
    "## üì¶ Section 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation cell - Run ONCE, then RESTART kernel\n",
    "print(\"üîß Installing compatible packages for Kaggle...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Fix NumPy/Matplotlib compatibility\n",
    "!pip install -q \"numpy<2.0\" --force-reinstall\n",
    "\n",
    "# Fix OpenCV compatibility\n",
    "!pip uninstall -y opencv-python opencv-python-headless opencv-contrib-python 2>/dev/null\n",
    "!pip install -q opencv-python-headless==4.8.1.78\n",
    "\n",
    "# Install YOLO\n",
    "!pip install -q --no-deps ultralytics\n",
    "!pip install -q pillow tqdm pyyaml\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ Installation complete!\")\n",
    "print(\"‚ö†Ô∏è  RESTART KERNEL NOW: Run ‚Üí Restart Session\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2891a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üì¶ PyTorch version: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7433d7c",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv10Config:\n",
    "    \"\"\"Configuration for YOLOv10 training on TBX11K dataset - OPTIMIZED FOR SMALL DATASET\"\"\"\n",
    "    \n",
    "    # ========== DATASET PATHS (KAGGLE OPTIMIZED) ==========\n",
    "    # Update this to match your Kaggle dataset name after upload\n",
    "    DATASET_NAME = 'tbx11k-small-balanced'  # Change this to your uploaded dataset name\n",
    "    DATASET_PATH = f'/kaggle/input/{DATASET_NAME}'\n",
    "    DATA_YAML = f'{DATASET_PATH}/data.yaml'\n",
    "    \n",
    "    # ========== OUTPUT PATHS ==========\n",
    "    OUTPUT_DIR = Path('/kaggle/working')\n",
    "    MODEL_DIR = OUTPUT_DIR / 'yolov10_model'\n",
    "    PLOTS_DIR = OUTPUT_DIR / 'yolov10_plots'\n",
    "    RESULTS_DIR = OUTPUT_DIR / 'yolov10_results'\n",
    "    \n",
    "    # Create directories\n",
    "    for directory in [MODEL_DIR, PLOTS_DIR, RESULTS_DIR]:\n",
    "        directory.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ========== MODEL CONFIGURATION ==========\n",
    "    MODEL_NAME = 'YOLOv10n'\n",
    "    MODEL_WEIGHTS = 'yolov10n.pt'\n",
    "    \n",
    "    # ========== TRAINING HYPERPARAMETERS (OPTIMIZED FOR SMALL DATA) ==========\n",
    "    IMG_SIZE = 640  # Increased from 512 for more detail\n",
    "    BATCH_SIZE = 8  # Reduced from 16 for more gradient updates\n",
    "    EPOCHS = 30     # Reduced from 150 for faster training (your request)\n",
    "    PATIENCE = 15   # Adjusted proportionally\n",
    "    WORKERS = 0     # Avoid multiprocessing issues\n",
    "    DEVICE = 0\n",
    "    \n",
    "    # ========== OPTIMIZER SETTINGS (CONSERVATIVE FOR SMALL DATA) ==========\n",
    "    OPTIMIZER = 'AdamW'\n",
    "    LR0 = 0.0005    # Reduced from 0.001 for gentler learning\n",
    "    LRF = 0.005     # Gentler decay\n",
    "    MOMENTUM = 0.937\n",
    "    WEIGHT_DECAY = 0.001  # Increased regularization\n",
    "    WARMUP_EPOCHS = 5     # Longer warmup\n",
    "    WARMUP_MOMENTUM = 0.8\n",
    "    WARMUP_BIAS_LR = 0.1\n",
    "    \n",
    "    # ========== LOSS WEIGHTS ==========\n",
    "    BOX = 7.5\n",
    "    CLS = 1.5  # Increased for better class distinction\n",
    "    DFL = 1.5\n",
    "    \n",
    "    # ========== AGGRESSIVE AUGMENTATION (KEY FOR SMALL DATASETS!) ==========\n",
    "    DEGREES = 25.0      # Increased rotation range\n",
    "    TRANSLATE = 0.2     # Increased translation\n",
    "    SCALE = 0.5         # Increased scaling variation\n",
    "    SHEAR = 10.0        # Increased shearing\n",
    "    PERSPECTIVE = 0.001\n",
    "    FLIPUD = 0.0        # No vertical flip for X-rays\n",
    "    FLIPLR = 0.5        # Horizontal flip\n",
    "    MOSAIC = 1.0        # ALWAYS use mosaic (combines 4 images)\n",
    "    MIXUP = 0.3         # Increased from 0.15\n",
    "    COPY_PASTE = 0.3    # Increased from 0.1 - copies TB lesions\n",
    "    HSV_H = 0.0         # No hue (grayscale X-rays)\n",
    "    HSV_S = 0.0         # No saturation\n",
    "    HSV_V = 0.6         # Increased brightness variation\n",
    "    ERASING = 0.5       # Increased random erasing\n",
    "    \n",
    "    # ========== REGULARIZATION ==========\n",
    "    DROPOUT = 0.3\n",
    "    LABEL_SMOOTHING = 0.1\n",
    "    \n",
    "    # ========== INFERENCE ==========\n",
    "    CONF_THRESHOLD = 0.20  # Lowered from 0.25 to increase recall\n",
    "    IOU_THRESHOLD = 0.45\n",
    "    \n",
    "    # ========== DATASET INFO ==========\n",
    "    NUM_CLASSES = 3\n",
    "    CLASS_NAMES = {\n",
    "        0: 'Active Tuberculosis',\n",
    "        1: 'Obsolete Pulmonary TB',\n",
    "        2: 'Pulmonary Tuberculosis'\n",
    "    }\n",
    "    \n",
    "    # ========== VISUALIZATION ==========\n",
    "    DPI = 150\n",
    "    FIGSIZE = (15, 10)\n",
    "\n",
    "config = YOLOv10Config()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFIGURATION - OPTIMIZED FOR SMALL DATASET (800 images)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Dataset: {config.DATASET_PATH}\")\n",
    "print(f\"Data YAML: {config.DATA_YAML}\")\n",
    "print(f\"Model: {config.MODEL_NAME}\")\n",
    "print(f\"Image Size: {config.IMG_SIZE}x{config.IMG_SIZE} (increased from 512)\")\n",
    "print(f\"Batch Size: {config.BATCH_SIZE} (reduced for more updates)\")\n",
    "print(f\"Epochs: {config.EPOCHS}\")\n",
    "print(f\"Patience: {config.PATIENCE}\")\n",
    "print(f\"Classes: {config.NUM_CLASSES}\")\n",
    "print(f\"Learning Rate: {config.LR0} (conservative)\")\n",
    "print(f\"Augmentation: AGGRESSIVE (Mosaic=1.0, MixUp=0.3, CopyPaste=0.3)\")\n",
    "print(f\"Output: {config.OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY CHANGES FOR SMALL DATASET:\")\n",
    "print(\"  - Batch size: 16 -> 8 (more gradient updates)\")\n",
    "print(\"  - Image size: 512 -> 640 (capture more detail)\")\n",
    "print(\"  - LR: 0.001 -> 0.0005 (gentler learning)\")\n",
    "print(\"  - Mosaic: 0.8 -> 1.0 (always combine 4 images)\")\n",
    "print(\"  - MixUp: 0.15 -> 0.3 (more mixing)\")\n",
    "print(\"  - CopyPaste: 0.1 -> 0.3 (copy TB lesions)\")\n",
    "print(\"  - Rotation: +/-15 deg -> +/-25 deg (more variation)\")\n",
    "print(\"  - Scale: +/-30% -> +/-50% (diverse sizes)\")\n",
    "print(\"  - Brightness: 40% -> 60% (strong variation)\")\n",
    "print(\"  - Erasing: 40% -> 50% (simulate occlusions)\")\n",
    "print(\"  - Conf threshold: 0.25 -> 0.20 (increase recall)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"IMPORTANT: Update DATASET_NAME in config to match your Kaggle dataset!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397ee18",
   "metadata": {},
   "source": [
    "## üìä Section 3: Dataset Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "print(\"üîç Verifying dataset structure...\\n\")\n",
    "\n",
    "dataset_path = Path(config.DATASET_PATH)\n",
    "\n",
    "# Check main directories\n",
    "train_img_dir = dataset_path / 'images' / 'train'\n",
    "train_lbl_dir = dataset_path / 'labels' / 'train'\n",
    "val_img_dir = dataset_path / 'images' / 'val'\n",
    "val_lbl_dir = dataset_path / 'labels' / 'val'\n",
    "\n",
    "# Count files\n",
    "train_images = list(train_img_dir.glob('*.png')) if train_img_dir.exists() else []\n",
    "train_labels = list(train_lbl_dir.glob('*.txt')) if train_lbl_dir.exists() else []\n",
    "val_images = list(val_img_dir.glob('*.png')) if val_img_dir.exists() else []\n",
    "val_labels = list(val_lbl_dir.glob('*.txt')) if val_lbl_dir.exists() else []\n",
    "\n",
    "print(\"üìÇ Dataset Structure:\")\n",
    "print(f\"  ‚îú‚îÄ Training Images: {len(train_images)}\")\n",
    "print(f\"  ‚îú‚îÄ Training Labels: {len(train_labels)}\")\n",
    "print(f\"  ‚îú‚îÄ Validation Images: {len(val_images)}\")\n",
    "print(f\"  ‚îî‚îÄ Validation Labels: {len(val_labels)}\")\n",
    "\n",
    "# Check data.yaml\n",
    "data_yaml_path = Path(config.DATA_YAML)\n",
    "if data_yaml_path.exists():\n",
    "    print(f\"\\n‚úÖ data.yaml found: {data_yaml_path}\")\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        print(\"\\nüìÑ data.yaml content:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  data.yaml not found at: {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644072d6",
   "metadata": {},
   "source": [
    "## üöÄ Section 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef06b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üöÄ STARTING YOLOV10 TRAINING - OPTIMIZED FOR SMALL DATASET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize model\n",
    "print(f\"\\nüì• Loading pretrained weights: {config.MODEL_WEIGHTS}\")\n",
    "model = YOLO(config.MODEL_WEIGHTS)\n",
    "\n",
    "# Training arguments\n",
    "train_args = {\n",
    "    'data': str(config.DATA_YAML),\n",
    "    'epochs': config.EPOCHS,\n",
    "    'imgsz': config.IMG_SIZE,\n",
    "    'batch': config.BATCH_SIZE,\n",
    "    'device': config.DEVICE,\n",
    "    'workers': config.WORKERS,\n",
    "    'patience': config.PATIENCE,\n",
    "    'save': True,\n",
    "    'save_period': 10,\n",
    "    'cache': False,\n",
    "    'project': str(config.MODEL_DIR),\n",
    "    'name': 'train',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': True,\n",
    "    'optimizer': config.OPTIMIZER,\n",
    "    'verbose': True,\n",
    "    'seed': 42,\n",
    "    'deterministic': False,\n",
    "    'single_cls': False,\n",
    "    'rect': False,\n",
    "    'cos_lr': True,\n",
    "    'close_mosaic': 5,\n",
    "    'resume': False,\n",
    "    'amp': False,\n",
    "    'fraction': 1.0,\n",
    "    'profile': False,\n",
    "    'freeze': None,\n",
    "    'plots': True,\n",
    "    \n",
    "    # Hyperparameters (OPTIMIZED)\n",
    "    'lr0': config.LR0,\n",
    "    'lrf': config.LRF,\n",
    "    'momentum': config.MOMENTUM,\n",
    "    'weight_decay': config.WEIGHT_DECAY,\n",
    "    'warmup_epochs': config.WARMUP_EPOCHS,\n",
    "    'warmup_momentum': config.WARMUP_MOMENTUM,\n",
    "    'warmup_bias_lr': config.WARMUP_BIAS_LR,\n",
    "    'box': config.BOX,\n",
    "    'cls': config.CLS,\n",
    "    'dfl': config.DFL,\n",
    "    'dropout': config.DROPOUT,\n",
    "    'label_smoothing': config.LABEL_SMOOTHING,\n",
    "    \n",
    "    # AGGRESSIVE Augmentation (KEY FOR SMALL DATA!)\n",
    "    'hsv_h': config.HSV_H,\n",
    "    'hsv_s': config.HSV_S,\n",
    "    'hsv_v': config.HSV_V,\n",
    "    'degrees': config.DEGREES,\n",
    "    'translate': config.TRANSLATE,\n",
    "    'scale': config.SCALE,\n",
    "    'shear': config.SHEAR,\n",
    "    'perspective': config.PERSPECTIVE,\n",
    "    'flipud': config.FLIPUD,\n",
    "    'fliplr': config.FLIPLR,\n",
    "    'mosaic': config.MOSAIC,\n",
    "    'mixup': config.MIXUP,\n",
    "    'copy_paste': config.COPY_PASTE,\n",
    "    'erasing': config.ERASING,\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Training Configuration (OPTIMIZED FOR SMALL DATASET):\")\n",
    "print(f\"  ‚Ä¢ Epochs: {config.EPOCHS} (reduced for time constraint)\")\n",
    "print(f\"  ‚Ä¢ Batch Size: {config.BATCH_SIZE} ‚¨áÔ∏è (more updates)\")\n",
    "print(f\"  ‚Ä¢ Image Size: {config.IMG_SIZE} ‚¨ÜÔ∏è (more detail)\")\n",
    "print(f\"  ‚Ä¢ Optimizer: {config.OPTIMIZER}\")\n",
    "print(f\"  ‚Ä¢ Learning Rate: {config.LR0} ‚¨áÔ∏è (conservative)\")\n",
    "print(f\"  ‚Ä¢ Weight Decay: {config.WEIGHT_DECAY} ‚¨ÜÔ∏è (regularization)\")\n",
    "print(f\"  ‚Ä¢ Dropout: {config.DROPOUT}\")\n",
    "print(f\"  ‚Ä¢ Label Smoothing: {config.LABEL_SMOOTHING}\")\n",
    "print(f\"\\nüé® AGGRESSIVE Augmentation (maximize 800 images):\")\n",
    "print(f\"  ‚Ä¢ Mosaic: {config.MOSAIC} (ALWAYS combine 4 images)\")\n",
    "print(f\"  ‚Ä¢ MixUp: {config.MIXUP}\")\n",
    "print(f\"  ‚Ä¢ Copy-Paste: {config.COPY_PASTE} (copy TB lesions)\")\n",
    "print(f\"  ‚Ä¢ Rotation: ¬±{config.DEGREES}¬∞\")\n",
    "print(f\"  ‚Ä¢ Translation: {config.TRANSLATE*100}%\")\n",
    "print(f\"  ‚Ä¢ Scale: ¬±{config.SCALE*100}%\")\n",
    "print(f\"  ‚Ä¢ Shear: ¬±{config.SHEAR}¬∞\")\n",
    "print(f\"  ‚Ä¢ Brightness: {config.HSV_V*100}% variation\")\n",
    "print(f\"  ‚Ä¢ Random Erasing: {config.ERASING*100}%\")\n",
    "print(f\"  ‚Ä¢ Horizontal Flip: {config.FLIPLR*100}%\")\n",
    "\n",
    "print(\"\\n‚è≥ Training started... This will take approximately 15-20 minutes.\\n\")\n",
    "print(\"üéØ Expected improvement over baseline:\")\n",
    "print(\"   mAP@0.5: 0.24 ‚Üí 0.35-0.45 (+46-88%)\")\n",
    "print(\"   Precision: 0.30 ‚Üí 0.45-0.55\")\n",
    "print(\"   Recall: 0.22 ‚Üí 0.35-0.45\\n\")\n",
    "\n",
    "# Start training\n",
    "start_time = time.time()\n",
    "results = model.train(**train_args)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚è±Ô∏è  Training Time: {training_time/60:.2f} minutes ({training_time/3600:.2f} hours)\")\n",
    "print(f\"üíæ Model saved to: {config.MODEL_DIR / 'train' / 'weights' / 'best.pt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7d234",
   "metadata": {},
   "source": [
    "## üìà Section 5: Validation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c09c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä VALIDATING YOLOV10 MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "best_model_path = config.MODEL_DIR / 'train' / 'weights' / 'best.pt'\n",
    "best_model = YOLO(str(best_model_path))\n",
    "\n",
    "print(f\"\\nüì• Loaded best model: {best_model_path}\")\n",
    "\n",
    "# Run validation\n",
    "print(\"\\n‚è≥ Running validation...\\n\")\n",
    "val_results = best_model.val(\n",
    "    data=str(config.DATA_YAML),\n",
    "    split='val',\n",
    "    imgsz=config.IMG_SIZE,\n",
    "    batch=config.BATCH_SIZE,\n",
    "    conf=config.CONF_THRESHOLD,\n",
    "    iou=config.IOU_THRESHOLD,\n",
    "    device=config.DEVICE,\n",
    "    workers=config.WORKERS,\n",
    "    plots=True,\n",
    "    save_json=True,\n",
    "    project=str(config.RESULTS_DIR),\n",
    "    name='validation',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "# Extract metrics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà VALIDATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  ‚Ä¢ mAP@0.5:     {val_results.box.map50:.4f}\")\n",
    "print(f\"  ‚Ä¢ mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision:    {val_results.box.mp:.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall:       {val_results.box.mr:.4f}\")\n",
    "print(f\"  ‚Ä¢ Fitness:      {val_results.fitness:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save metrics to JSON\n",
    "metrics = {\n",
    "    'model': config.MODEL_NAME,\n",
    "    'epochs': config.EPOCHS,\n",
    "    'training_time_minutes': training_time / 60,\n",
    "    'mAP50': float(val_results.box.map50),\n",
    "    'mAP50_95': float(val_results.box.map),\n",
    "    'precision': float(val_results.box.mp),\n",
    "    'recall': float(val_results.box.mr),\n",
    "    'fitness': float(val_results.fitness),\n",
    "}\n",
    "\n",
    "metrics_file = config.RESULTS_DIR / 'yolov10_metrics.json'\n",
    "with open(metrics_file, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Metrics saved to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d0291",
   "metadata": {},
   "source": [
    "## üìä Section 6: Training Curves Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c73866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training results\n",
    "results_csv = config.MODEL_DIR / 'train' / 'results.csv'\n",
    "\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Create comprehensive training curves\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "    fig.suptitle('YOLOv10 Training Curves - Complete Analysis', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    epochs = df['epoch'] if 'epoch' in df.columns else range(len(df))\n",
    "    \n",
    "    # Plot 1: mAP@0.5\n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[0, 0].plot(epochs, df['metrics/mAP50(B)'], linewidth=2.5, color='blue', label='mAP@0.5')\n",
    "        axes[0, 0].fill_between(epochs, df['metrics/mAP50(B)'], alpha=0.3, color='blue')\n",
    "        axes[0, 0].set_title('mAP@0.5', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('mAP@0.5')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Plot 2: mAP@0.5:0.95\n",
    "    if 'metrics/mAP50-95(B)' in df.columns:\n",
    "        axes[0, 1].plot(epochs, df['metrics/mAP50-95(B)'], linewidth=2.5, color='green', label='mAP@0.5:0.95')\n",
    "        axes[0, 1].fill_between(epochs, df['metrics/mAP50-95(B)'], alpha=0.3, color='green')\n",
    "        axes[0, 1].set_title('mAP@0.5:0.95', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mAP@0.5:0.95')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # Plot 3: Precision\n",
    "    if 'metrics/precision(B)' in df.columns:\n",
    "        axes[0, 2].plot(epochs, df['metrics/precision(B)'], linewidth=2.5, color='orange', label='Precision')\n",
    "        axes[0, 2].fill_between(epochs, df['metrics/precision(B)'], alpha=0.3, color='orange')\n",
    "        axes[0, 2].set_title('Precision', fontsize=14, fontweight='bold')\n",
    "        axes[0, 2].set_xlabel('Epoch')\n",
    "        axes[0, 2].set_ylabel('Precision')\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        axes[0, 2].legend()\n",
    "    \n",
    "    # Plot 4: Recall\n",
    "    if 'metrics/recall(B)' in df.columns:\n",
    "        axes[1, 0].plot(epochs, df['metrics/recall(B)'], linewidth=2.5, color='red', label='Recall')\n",
    "        axes[1, 0].fill_between(epochs, df['metrics/recall(B)'], alpha=0.3, color='red')\n",
    "        axes[1, 0].set_title('Recall', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Recall')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    # Plot 5: Box Loss\n",
    "    if 'train/box_loss' in df.columns and 'val/box_loss' in df.columns:\n",
    "        axes[1, 1].plot(epochs, df['train/box_loss'], linewidth=2, label='Train', color='blue')\n",
    "        axes[1, 1].plot(epochs, df['val/box_loss'], linewidth=2, label='Val', color='red')\n",
    "        axes[1, 1].set_title('Box Loss', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    # Plot 6: Class Loss\n",
    "    if 'train/cls_loss' in df.columns and 'val/cls_loss' in df.columns:\n",
    "        axes[1, 2].plot(epochs, df['train/cls_loss'], linewidth=2, label='Train', color='blue')\n",
    "        axes[1, 2].plot(epochs, df['val/cls_loss'], linewidth=2, label='Val', color='red')\n",
    "        axes[1, 2].set_title('Classification Loss', fontsize=14, fontweight='bold')\n",
    "        axes[1, 2].set_xlabel('Epoch')\n",
    "        axes[1, 2].set_ylabel('Loss')\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        axes[1, 2].legend()\n",
    "    \n",
    "    # Plot 7: DFL Loss\n",
    "    if 'train/dfl_loss' in df.columns and 'val/dfl_loss' in df.columns:\n",
    "        axes[2, 0].plot(epochs, df['train/dfl_loss'], linewidth=2, label='Train', color='blue')\n",
    "        axes[2, 0].plot(epochs, df['val/dfl_loss'], linewidth=2, label='Val', color='red')\n",
    "        axes[2, 0].set_title('DFL Loss', fontsize=14, fontweight='bold')\n",
    "        axes[2, 0].set_xlabel('Epoch')\n",
    "        axes[2, 0].set_ylabel('Loss')\n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "        axes[2, 0].legend()\n",
    "    \n",
    "    # Plot 8: F1 Score (calculated)\n",
    "    if 'metrics/precision(B)' in df.columns and 'metrics/recall(B)' in df.columns:\n",
    "        precision = df['metrics/precision(B)']\n",
    "        recall = df['metrics/recall(B)']\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        axes[2, 1].plot(epochs, f1, linewidth=2.5, color='purple', label='F1 Score')\n",
    "        axes[2, 1].fill_between(epochs, f1, alpha=0.3, color='purple')\n",
    "        axes[2, 1].set_title('F1 Score', fontsize=14, fontweight='bold')\n",
    "        axes[2, 1].set_xlabel('Epoch')\n",
    "        axes[2, 1].set_ylabel('F1 Score')\n",
    "        axes[2, 1].grid(True, alpha=0.3)\n",
    "        axes[2, 1].legend()\n",
    "    \n",
    "    # Plot 9: Learning Rate\n",
    "    if 'lr/pg0' in df.columns:\n",
    "        axes[2, 2].plot(epochs, df['lr/pg0'], linewidth=2, color='brown', label='Learning Rate')\n",
    "        axes[2, 2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        axes[2, 2].set_xlabel('Epoch')\n",
    "        axes[2, 2].set_ylabel('Learning Rate')\n",
    "        axes[2, 2].grid(True, alpha=0.3)\n",
    "        axes[2, 2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'training_curves.png'\n",
    "    plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Training curves saved to: {save_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Results CSV not found at: {results_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e1275",
   "metadata": {},
   "source": [
    "## üéØ Section 7: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for confusion matrix\n",
    "confusion_matrix_path = config.RESULTS_DIR / 'validation' / 'confusion_matrix.png'\n",
    "\n",
    "if confusion_matrix_path.exists():\n",
    "    print(\"üìä Displaying Confusion Matrix\\n\")\n",
    "    \n",
    "    img = Image.open(confusion_matrix_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 10))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('YOLOv10 - Confusion Matrix (Normalized)', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'confusion_matrix_display.png'\n",
    "    plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Confusion matrix saved to: {save_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Confusion matrix not found at: {confusion_matrix_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599e99c",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Section 8: Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4042833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"GENERATING SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get validation images with labels\n",
    "val_img_dir = Path(config.DATASET_PATH) / 'images' / 'val'\n",
    "val_lbl_dir = Path(config.DATASET_PATH) / 'labels' / 'val'\n",
    "\n",
    "# Check if directory exists\n",
    "if not val_img_dir.exists():\n",
    "    print(f\"ERROR: Validation image directory not found: {val_img_dir}\")\n",
    "    print(\"Please check your dataset path configuration.\")\n",
    "else:\n",
    "    val_images_with_labels = []\n",
    "    for img_path in val_img_dir.glob('*.png'):\n",
    "        label_path = val_lbl_dir / f\"{img_path.stem}.txt\"\n",
    "        if label_path.exists() and label_path.stat().st_size > 0:\n",
    "            val_images_with_labels.append(img_path)\n",
    "\n",
    "    if len(val_images_with_labels) == 0:\n",
    "        print(\"WARNING: No validation images with labels found!\")\n",
    "        print(f\"  - Checked directory: {val_img_dir}\")\n",
    "        print(f\"  - Total .png files: {len(list(val_img_dir.glob('*.png')))}\")\n",
    "        print(\"  - Images with non-empty labels: 0\")\n",
    "    else:\n",
    "        # Select random samples\n",
    "        num_samples = min(9, len(val_images_with_labels))\n",
    "        selected_samples = random.sample(val_images_with_labels, num_samples)\n",
    "\n",
    "        print(f\"\\nGenerating predictions for {num_samples} samples...\\n\")\n",
    "\n",
    "        # Create prediction grid\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "        axes = axes.flatten()\n",
    "        fig.suptitle('YOLOv10 - Sample Predictions on Validation Set', fontsize=18, fontweight='bold')\n",
    "\n",
    "        for idx, img_path in enumerate(selected_samples):\n",
    "            # Run prediction\n",
    "            results = best_model.predict(\n",
    "                source=str(img_path),\n",
    "                conf=config.CONF_THRESHOLD,\n",
    "                iou=config.IOU_THRESHOLD,\n",
    "                imgsz=config.IMG_SIZE,\n",
    "                device=config.DEVICE,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Get annotated image\n",
    "            annotated = results[0].plot()\n",
    "            annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display\n",
    "            axes[idx].imshow(annotated_rgb)\n",
    "            num_detections = len(results[0].boxes)\n",
    "            axes[idx].set_title(f'{img_path.stem}\\n({num_detections} detections)', \n",
    "                               fontsize=11, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_path = config.PLOTS_DIR / 'sample_predictions.png'\n",
    "        plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Sample predictions saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02af69",
   "metadata": {},
   "source": [
    "## üìä Section 9: Metrics Summary Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ea6a2",
   "metadata": {},
   "source": [
    "## üé® Section 8.5: Enhanced Detection Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 1: Prediction Grid with ALL Images (Even Without Detections)\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"CREATING COMPREHENSIVE PREDICTION VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get ALL validation images\n",
    "val_img_dir = Path(config.DATASET_PATH) / 'images' / 'val'\n",
    "\n",
    "# Check if directory exists\n",
    "if not val_img_dir.exists():\n",
    "    print(f\"ERROR: Validation directory not found: {val_img_dir}\")\n",
    "    print(\"Please verify your DATASET_PATH configuration.\")\n",
    "    all_val_images = []\n",
    "else:\n",
    "    all_val_images = list(val_img_dir.glob('*.png'))\n",
    "\n",
    "if len(all_val_images) == 0:\n",
    "    print(\"ERROR: No validation images found!\")\n",
    "    print(f\"  - Checked directory: {val_img_dir}\")\n",
    "    print(f\"  - Looking for: *.png files\")\n",
    "    print(\"\\nPossible solutions:\")\n",
    "    print(\"  1. Check if DATASET_NAME in config matches your Kaggle dataset\")\n",
    "    print(\"  2. Verify dataset structure: images/val/ folder exists\")\n",
    "    print(\"  3. Ensure images have .png extension\")\n",
    "else:\n",
    "    # Select 9 random images (regardless of labels)\n",
    "    num_samples = min(9, len(all_val_images))\n",
    "    selected_samples = random.sample(all_val_images, num_samples)\n",
    "    \n",
    "    print(f\"\\nGenerating predictions for {num_samples} validation images...\\n\")\n",
    "    \n",
    "    # Create prediction grid\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle('YOLOv10 - Sample Predictions on Validation Set', fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    for idx, img_path in enumerate(selected_samples):\n",
    "        try:\n",
    "            # Run prediction\n",
    "            results = best_model.predict(\n",
    "                source=str(img_path),\n",
    "                conf=config.CONF_THRESHOLD,\n",
    "                iou=config.IOU_THRESHOLD,\n",
    "                imgsz=config.IMG_SIZE,\n",
    "                device=config.DEVICE,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Get annotated image\n",
    "            annotated = results[0].plot()\n",
    "            annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display\n",
    "            axes[idx].imshow(annotated_rgb)\n",
    "            num_detections = len(results[0].boxes)\n",
    "            \n",
    "            # Color code title based on detections\n",
    "            if num_detections > 0:\n",
    "                title_color = 'green'\n",
    "                title = f'{img_path.stem}\\n{num_detections} detection(s)'\n",
    "            else:\n",
    "                title_color = 'red'\n",
    "                title = f'{img_path.stem}\\nNo detections'\n",
    "            \n",
    "            axes[idx].set_title(title, fontsize=11, fontweight='bold', color=title_color)\n",
    "            axes[idx].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Error processing {img_path.name}: {str(e)}\")\n",
    "            axes[idx].text(0.5, 0.5, f'Error: {img_path.stem}', ha='center', va='center')\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'sample_predictions.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Sample predictions saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 2: Confidence Distribution Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONFIDENCE SCORE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get validation images (use from previous cell if available)\n",
    "val_img_dir = Path(config.DATASET_PATH) / 'images' / 'val'\n",
    "if 'all_val_images' not in globals() or len(all_val_images) == 0:\n",
    "    if val_img_dir.exists():\n",
    "        all_val_images = list(val_img_dir.glob('*.png'))\n",
    "    else:\n",
    "        all_val_images = []\n",
    "\n",
    "# Check if we have images to analyze\n",
    "if len(all_val_images) == 0:\n",
    "    print(\"\\nERROR: No validation images found for analysis!\")\n",
    "    print(f\"  - Directory: {val_img_dir}\")\n",
    "    print(\"  - Please check your dataset configuration\")\n",
    "else:\n",
    "    # Run predictions on all validation images\n",
    "    all_confidences = []\n",
    "    all_classes = []\n",
    "    detection_stats = {'with_detection': 0, 'without_detection': 0}\n",
    "\n",
    "    print(f\"\\nAnalyzing {len(all_val_images)} validation images...\\n\")\n",
    "\n",
    "    for img_path in tqdm(all_val_images, desc=\"Processing\"):\n",
    "        try:\n",
    "            results = best_model.predict(\n",
    "                source=str(img_path),\n",
    "                conf=config.CONF_THRESHOLD,\n",
    "                iou=config.IOU_THRESHOLD,\n",
    "                imgsz=config.IMG_SIZE,\n",
    "                device=config.DEVICE,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            if len(results[0].boxes) > 0:\n",
    "                detection_stats['with_detection'] += 1\n",
    "                for box in results[0].boxes:\n",
    "                    all_confidences.append(float(box.conf.cpu()))\n",
    "                    all_classes.append(int(box.cls.cpu()))\n",
    "            else:\n",
    "                detection_stats['without_detection'] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"\\nWARNING: Error processing {img_path.name}: {str(e)}\")\n",
    "            detection_stats['without_detection'] += 1\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('YOLOv10 - Detection Confidence Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Confidence Distribution\n",
    "    if all_confidences:\n",
    "        axes[0, 0].hist(all_confidences, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        axes[0, 0].axvline(config.CONF_THRESHOLD, color='red', linestyle='--', \n",
    "                           label=f'Threshold: {config.CONF_THRESHOLD}', linewidth=2)\n",
    "        axes[0, 0].set_xlabel('Confidence Score', fontsize=12)\n",
    "        axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "        axes[0, 0].set_title(f'Confidence Score Distribution\\n(Total Detections: {len(all_confidences)})', fontweight='bold')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(alpha=0.3)\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, 'No Detections Found', ha='center', va='center', fontsize=14, color='red')\n",
    "        axes[0, 0].set_title('Confidence Score Distribution', fontweight='bold')\n",
    "\n",
    "    # 2. Detection Statistics\n",
    "    categories = ['Images with\\nDetections', 'Images without\\nDetections']\n",
    "    values = [detection_stats['with_detection'], detection_stats['without_detection']]\n",
    "    colors = ['#4CAF50', '#f44336']\n",
    "\n",
    "    axes[0, 1].bar(categories, values, color=colors, edgecolor='black', linewidth=2)\n",
    "    axes[0, 1].set_ylabel('Number of Images', fontsize=12)\n",
    "    axes[0, 1].set_title('Detection Coverage Analysis', fontweight='bold')\n",
    "    for i, v in enumerate(values):\n",
    "        axes[0, 1].text(i, v + max(values)*0.02 if max(values) > 0 else 0.5, str(v), \n",
    "                        ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "    # 3. Class Distribution\n",
    "    if all_classes:\n",
    "        class_counts = pd.Series(all_classes).value_counts().sort_index()\n",
    "        class_names = [config.CLASS_NAMES[i] for i in class_counts.index]\n",
    "        \n",
    "        axes[1, 0].barh(class_names, class_counts.values, color='coral', edgecolor='black')\n",
    "        axes[1, 0].set_xlabel('Number of Detections', fontsize=12)\n",
    "        axes[1, 0].set_title('Detections per Class', fontweight='bold')\n",
    "        for i, v in enumerate(class_counts.values):\n",
    "            axes[1, 0].text(v + max(class_counts.values)*0.02, i, str(v), \n",
    "                            va='center', fontweight='bold')\n",
    "        axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No Detections Found', ha='center', va='center', fontsize=14, color='red')\n",
    "        axes[1, 0].set_title('Detections per Class', fontweight='bold')\n",
    "\n",
    "    # 4. Confidence Box Plot by Class\n",
    "    if all_confidences and all_classes:\n",
    "        conf_by_class = pd.DataFrame({'Class': all_classes, 'Confidence': all_confidences})\n",
    "        conf_by_class['Class_Name'] = conf_by_class['Class'].map(lambda x: config.CLASS_NAMES[x])\n",
    "        \n",
    "        class_names_unique = conf_by_class['Class_Name'].unique()\n",
    "        box_data = [conf_by_class[conf_by_class['Class_Name'] == cn]['Confidence'].values \n",
    "                    for cn in class_names_unique]\n",
    "        \n",
    "        bp = axes[1, 1].boxplot(box_data, labels=class_names_unique, patch_artist=True)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set_facecolor('lightgreen')\n",
    "        axes[1, 1].set_ylabel('Confidence Score', fontsize=12)\n",
    "        axes[1, 1].set_title('Confidence Distribution by Class', fontweight='bold')\n",
    "        axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "        axes[1, 1].tick_params(axis='x', rotation=15)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No Detections Found', ha='center', va='center', fontsize=14, color='red')\n",
    "        axes[1, 1].set_title('Confidence Distribution by Class', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'confidence_analysis.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nConfidence analysis saved to: {save_path}\")\n",
    "    print(f\"\\nDetection Summary:\")\n",
    "    \n",
    "    # Safe division to avoid ZeroDivisionError\n",
    "    total_images = len(all_val_images)\n",
    "    if total_images > 0:\n",
    "        with_pct = (detection_stats['with_detection'] / total_images) * 100\n",
    "        without_pct = (detection_stats['without_detection'] / total_images) * 100\n",
    "        print(f\"   - Images with detections: {detection_stats['with_detection']} ({with_pct:.1f}%)\")\n",
    "        print(f\"   - Images without detections: {detection_stats['without_detection']} ({without_pct:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   - Images with detections: {detection_stats['with_detection']}\")\n",
    "        print(f\"   - Images without detections: {detection_stats['without_detection']}\")\n",
    "    \n",
    "    print(f\"   - Total detections: {len(all_confidences)}\")\n",
    "    \n",
    "    if all_confidences:\n",
    "        print(f\"   - Average confidence: {np.mean(all_confidences):.4f}\")\n",
    "        print(f\"   - Min confidence: {np.min(all_confidences):.4f}\")\n",
    "        print(f\"   - Max confidence: {np.max(all_confidences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ddb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 3: High-Confidence vs Low-Confidence Detections\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HIGH vs LOW CONFIDENCE DETECTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if we have confidence data from previous cell\n",
    "if 'all_confidences' not in globals() or len(all_confidences) == 0:\n",
    "    print(\"\\nWARNING: No detections found in previous analysis.\")\n",
    "    print(\"Skipping high vs low confidence comparison.\")\n",
    "else:\n",
    "    # Find images with high and low confidence detections\n",
    "    high_conf_images = []\n",
    "    low_conf_images = []\n",
    "    \n",
    "    threshold_high = 0.7\n",
    "    threshold_low = 0.4\n",
    "    \n",
    "    # Check if all_val_images exists and is not empty\n",
    "    if 'all_val_images' not in globals() or len(all_val_images) == 0:\n",
    "        val_img_dir = Path(config.DATASET_PATH) / 'images' / 'val'\n",
    "        if val_img_dir.exists():\n",
    "            all_val_images = list(val_img_dir.glob('*.png'))\n",
    "        else:\n",
    "            all_val_images = []\n",
    "    \n",
    "    if len(all_val_images) == 0:\n",
    "        print(\"\\nERROR: No validation images available for comparison\")\n",
    "    else:\n",
    "        for img_path in all_val_images:\n",
    "            try:\n",
    "                results = best_model.predict(\n",
    "                    source=str(img_path),\n",
    "                    conf=config.CONF_THRESHOLD,\n",
    "                    imgsz=config.IMG_SIZE,\n",
    "                    device=config.DEVICE,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                if len(results[0].boxes) > 0:\n",
    "                    max_conf = max([float(box.conf.cpu()) for box in results[0].boxes])\n",
    "                    if max_conf >= threshold_high:\n",
    "                        high_conf_images.append((img_path, results, max_conf))\n",
    "                    elif max_conf <= threshold_low:\n",
    "                        low_conf_images.append((img_path, results, max_conf))\n",
    "            except Exception as e:\n",
    "                continue  # Skip problematic images\n",
    "        \n",
    "        # Create comparison visualization\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('YOLOv10 - Confidence Comparison: High vs Low', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot high confidence (top row)\n",
    "        for idx in range(3):\n",
    "            if idx < len(high_conf_images):\n",
    "                img_path, results, conf = high_conf_images[idx]\n",
    "                annotated = results[0].plot()\n",
    "                annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "                axes[0, idx].imshow(annotated_rgb)\n",
    "                axes[0, idx].set_title(f'HIGH CONF: {conf:.3f}\\n{img_path.stem}', \n",
    "                                      fontsize=10, fontweight='bold', color='green')\n",
    "            else:\n",
    "                axes[0, idx].text(0.5, 0.5, 'No High\\nConfidence\\nDetections', \n",
    "                                ha='center', va='center', fontsize=12)\n",
    "            axes[0, idx].axis('off')\n",
    "        \n",
    "        # Plot low confidence (bottom row)\n",
    "        for idx in range(3):\n",
    "            if idx < len(low_conf_images):\n",
    "                img_path, results, conf = low_conf_images[idx]\n",
    "                annotated = results[0].plot()\n",
    "                annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "                axes[1, idx].imshow(annotated_rgb)\n",
    "                axes[1, idx].set_title(f'LOW CONF: {conf:.3f}\\n{img_path.stem}', \n",
    "                                      fontsize=10, fontweight='bold', color='orange')\n",
    "            else:\n",
    "                axes[1, idx].text(0.5, 0.5, 'No Low\\nConfidence\\nDetections', \n",
    "                                ha='center', va='center', fontsize=12)\n",
    "            axes[1, idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = config.PLOTS_DIR / 'confidence_comparison.png'\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nConfidence comparison saved to: {save_path}\")\n",
    "        print(f\"   - High confidence images (>={threshold_high}): {len(high_conf_images)}\")\n",
    "        print(f\"   - Low confidence images (<={threshold_low}): {len(low_conf_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 4: Training Curves from results.csv\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà TRAINING CURVES VISUALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load results CSV\n",
    "results_csv = config.MODEL_DIR / 'train' / 'results.csv'\n",
    "\n",
    "if results_csv.exists():\n",
    "    results_df = pd.read_csv(results_csv)\n",
    "    results_df.columns = results_df.columns.str.strip()  # Remove whitespace\n",
    "    \n",
    "    # Create comprehensive training curves\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "    fig.suptitle('YOLOv10 - Training Progress Curves', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    epochs = results_df.index + 1\n",
    "    \n",
    "    # 1. Loss Curves\n",
    "    axes[0, 0].plot(epochs, results_df['train/box_loss'], label='Train Box Loss', linewidth=2, marker='o', markersize=3)\n",
    "    axes[0, 0].plot(epochs, results_df['val/box_loss'], label='Val Box Loss', linewidth=2, marker='s', markersize=3)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Box Loss (Train vs Val)', fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Classification Loss\n",
    "    axes[0, 1].plot(epochs, results_df['train/cls_loss'], label='Train Cls Loss', linewidth=2, marker='o', markersize=3, color='orange')\n",
    "    axes[0, 1].plot(epochs, results_df['val/cls_loss'], label='Val Cls Loss', linewidth=2, marker='s', markersize=3, color='red')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_title('Classification Loss (Train vs Val)', fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # 3. mAP@0.5\n",
    "    axes[1, 0].plot(epochs, results_df['metrics/mAP50(B)'], linewidth=2, marker='D', markersize=4, color='green')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('mAP@0.5')\n",
    "    axes[1, 0].set_title('mAP@0.5 Progress', fontweight='bold')\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    axes[1, 0].fill_between(epochs, results_df['metrics/mAP50(B)'], alpha=0.3, color='green')\n",
    "    \n",
    "    # 4. mAP@0.5:0.95\n",
    "    axes[1, 1].plot(epochs, results_df['metrics/mAP50-95(B)'], linewidth=2, marker='D', markersize=4, color='blue')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('mAP@0.5:0.95')\n",
    "    axes[1, 1].set_title('mAP@0.5:0.95 Progress', fontweight='bold')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    axes[1, 1].fill_between(epochs, results_df['metrics/mAP50-95(B)'], alpha=0.3, color='blue')\n",
    "    \n",
    "    # 5. Precision & Recall\n",
    "    axes[2, 0].plot(epochs, results_df['metrics/precision(B)'], label='Precision', linewidth=2, marker='o', markersize=3, color='purple')\n",
    "    axes[2, 0].plot(epochs, results_df['metrics/recall(B)'], label='Recall', linewidth=2, marker='s', markersize=3, color='brown')\n",
    "    axes[2, 0].set_xlabel('Epoch')\n",
    "    axes[2, 0].set_ylabel('Score')\n",
    "    axes[2, 0].set_title('Precision & Recall Progress', fontweight='bold')\n",
    "    axes[2, 0].legend()\n",
    "    axes[2, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # 6. Learning Rate\n",
    "    axes[2, 1].plot(epochs, results_df['lr/pg0'], label='LR Group 0', linewidth=2, marker='o', markersize=3)\n",
    "    axes[2, 1].plot(epochs, results_df['lr/pg1'], label='LR Group 1', linewidth=2, marker='s', markersize=3)\n",
    "    axes[2, 1].plot(epochs, results_df['lr/pg2'], label='LR Group 2', linewidth=2, marker='^', markersize=3)\n",
    "    axes[2, 1].set_xlabel('Epoch')\n",
    "    axes[2, 1].set_ylabel('Learning Rate')\n",
    "    axes[2, 1].set_title('Learning Rate Schedule', fontweight='bold')\n",
    "    axes[2, 1].legend()\n",
    "    axes[2, 1].grid(alpha=0.3)\n",
    "    axes[2, 1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = config.PLOTS_DIR / 'training_curves_detailed.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training curves saved to: {save_path}\")\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(f\"\\nüìä Final Epoch Metrics:\")\n",
    "    print(f\"   ‚Ä¢ mAP@0.5: {results_df['metrics/mAP50(B)'].iloc[-1]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ mAP@0.5:0.95: {results_df['metrics/mAP50-95(B)'].iloc[-1]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Precision: {results_df['metrics/precision(B)'].iloc[-1]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Recall: {results_df['metrics/recall(B)'].iloc[-1]:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Results CSV not found at: {results_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae59797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive metrics summary\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä YOLOV10 FINAL METRICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Model',\n",
    "        'Epochs Trained',\n",
    "        'Training Time (min)',\n",
    "        'mAP@0.5',\n",
    "        'mAP@0.5:0.95',\n",
    "        'Precision',\n",
    "        'Recall',\n",
    "        'F1 Score',\n",
    "        'Fitness Score',\n",
    "        'Image Size',\n",
    "        'Batch Size',\n",
    "        'Optimizer',\n",
    "        'Learning Rate',\n",
    "    ],\n",
    "    'Value': [\n",
    "        config.MODEL_NAME,\n",
    "        config.EPOCHS,\n",
    "        f\"{training_time/60:.2f}\",\n",
    "        f\"{float(val_results.box.map50):.4f}\",\n",
    "        f\"{float(val_results.box.map):.4f}\",\n",
    "        f\"{float(val_results.box.mp):.4f}\",\n",
    "        f\"{float(val_results.box.mr):.4f}\",\n",
    "        f\"{2 * (float(val_results.box.mp) * float(val_results.box.mr)) / (float(val_results.box.mp) + float(val_results.box.mr) + 1e-6):.4f}\",\n",
    "        f\"{float(val_results.fitness):.4f}\",\n",
    "        f\"{config.IMG_SIZE}x{config.IMG_SIZE}\",\n",
    "        config.BATCH_SIZE,\n",
    "        config.OPTIMIZER,\n",
    "        config.LR0,\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display styled table\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=summary_df.values, colLabels=summary_df.columns,\n",
    "                cellLoc='left', loc='center',\n",
    "                colWidths=[0.6, 0.4])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(summary_df.columns)):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Alternate row colors\n",
    "for i in range(1, len(summary_df) + 1):\n",
    "    for j in range(len(summary_df.columns)):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#f0f0f0')\n",
    "\n",
    "plt.title('YOLOv10 Training & Validation Metrics', fontsize=16, fontweight='bold', pad=20)\n",
    "save_path = config.PLOTS_DIR / 'metrics_summary.png'\n",
    "plt.savefig(save_path, dpi=config.DPI, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Metrics summary saved to: {save_path}\")\n",
    "\n",
    "# Also save as CSV\n",
    "csv_path = config.RESULTS_DIR / 'metrics_summary.csv'\n",
    "summary_df.to_csv(csv_path, index=False)\n",
    "print(f\"‚úÖ Metrics CSV saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a11c7c",
   "metadata": {},
   "source": [
    "## üìã Section 10: Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a554c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive markdown report\n",
    "report_path = config.RESULTS_DIR / 'yolov10_training_report.md'\n",
    "\n",
    "report_content = f\"\"\"# YOLOv10 Training Report - TBX11K Tuberculosis Detection\n",
    "\n",
    "**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n",
    "**Student:** Turjo Khan  \n",
    "**Institution:** East West University  \n",
    "**Course:** CSE475 - Machine Learning Lab\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Model Information\n",
    "\n",
    "- **Model:** {config.MODEL_NAME}\n",
    "- **Architecture:** YOLOv10 Nano\n",
    "- **Pretrained Weights:** {config.MODEL_WEIGHTS}\n",
    "- **Task:** Object Detection (Tuberculosis in Chest X-rays)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dataset\n",
    "\n",
    "- **Dataset:** TBX11K (Balanced)\n",
    "- **Training Images:** {len(train_images)}\n",
    "- **Validation Images:** {len(val_images)}\n",
    "- **Classes:** {config.NUM_CLASSES}\n",
    "  - Class 0: {config.CLASS_NAMES[0]}\n",
    "  - Class 1: {config.CLASS_NAMES[1]}\n",
    "  - Class 2: {config.CLASS_NAMES[2]}\n",
    "- **Image Size:** {config.IMG_SIZE}x{config.IMG_SIZE}\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Training Configuration\n",
    "\n",
    "### Hyperparameters\n",
    "- **Epochs:** {config.EPOCHS}\n",
    "- **Batch Size:** {config.BATCH_SIZE}\n",
    "- **Optimizer:** {config.OPTIMIZER}\n",
    "- **Initial Learning Rate:** {config.LR0}\n",
    "- **Final LR Factor:** {config.LRF}\n",
    "- **Momentum:** {config.MOMENTUM}\n",
    "- **Weight Decay:** {config.WEIGHT_DECAY}\n",
    "- **Warmup Epochs:** {config.WARMUP_EPOCHS}\n",
    "- **Patience:** {config.PATIENCE}\n",
    "\n",
    "### Loss Weights\n",
    "- **Box Loss:** {config.BOX}\n",
    "- **Class Loss:** {config.CLS}\n",
    "- **DFL Loss:** {config.DFL}\n",
    "\n",
    "### Data Augmentation\n",
    "- **Rotation:** ¬±{config.DEGREES}¬∞\n",
    "- **Translation:** {config.TRANSLATE * 100}%\n",
    "- **Scaling:** ¬±{config.SCALE * 100}%\n",
    "- **Shearing:** ¬±{config.SHEAR}¬∞\n",
    "- **Horizontal Flip:** {config.FLIPLR * 100}%\n",
    "- **Mosaic:** {config.MOSAIC * 100}%\n",
    "- **MixUp:** {config.MIXUP * 100}%\n",
    "- **Copy-Paste:** {config.COPY_PASTE * 100}%\n",
    "- **Random Erasing:** {config.ERASING * 100}%\n",
    "- **HSV Augmentation:** H={config.HSV_H}, S={config.HSV_S}, V={config.HSV_V}\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Training Results\n",
    "\n",
    "- **Training Time:** {training_time/60:.2f} minutes ({training_time/3600:.2f} hours)\n",
    "- **Best Model Path:** `{best_model_path}`\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Validation Metrics\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **mAP@0.5** | {float(val_results.box.map50):.4f} |\n",
    "| **mAP@0.5:0.95** | {float(val_results.box.map):.4f} |\n",
    "| **Precision** | {float(val_results.box.mp):.4f} |\n",
    "| **Recall** | {float(val_results.box.mr):.4f} |\n",
    "| **F1 Score** | {2 * (float(val_results.box.mp) * float(val_results.box.mr)) / (float(val_results.box.mp) + float(val_results.box.mr) + 1e-6):.4f} |\n",
    "| **Fitness** | {float(val_results.fitness):.4f} |\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Output Files\n",
    "\n",
    "### Models\n",
    "- Best weights: `{config.MODEL_DIR / 'train' / 'weights' / 'best.pt'}`\n",
    "- Last weights: `{config.MODEL_DIR / 'train' / 'weights' / 'last.pt'}`\n",
    "\n",
    "### Visualizations\n",
    "- Training curves: `{config.PLOTS_DIR / 'training_curves.png'}`\n",
    "- Confusion matrix: `{config.PLOTS_DIR / 'confusion_matrix_display.png'}`\n",
    "- Sample predictions: `{config.PLOTS_DIR / 'sample_predictions.png'}`\n",
    "- Metrics summary: `{config.PLOTS_DIR / 'metrics_summary.png'}`\n",
    "\n",
    "### Results\n",
    "- Metrics JSON: `{config.RESULTS_DIR / 'yolov10_metrics.json'}`\n",
    "- Metrics CSV: `{config.RESULTS_DIR / 'metrics_summary.csv'}`\n",
    "- Training CSV: `{config.MODEL_DIR / 'train' / 'results.csv'}`\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclusion\n",
    "\n",
    "YOLOv10 training completed successfully with {config.EPOCHS} epochs. The model achieved:\n",
    "- **mAP@0.5 of {float(val_results.box.map50):.4f}**\n",
    "- **Training time of {training_time/60:.2f} minutes**\n",
    "\n",
    "All visualizations and metrics have been saved for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "*Generated automatically by YOLOv10 training notebook*\n",
    "\"\"\"\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã YOLOV10 TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n‚úÖ Final report saved to: {report_path}\")\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"  ‚Ä¢ Model: {config.MODEL_NAME}\")\n",
    "print(f\"  ‚Ä¢ Epochs: {config.EPOCHS}\")\n",
    "print(f\"  ‚Ä¢ Training Time: {training_time/60:.2f} min\")\n",
    "print(f\"  ‚Ä¢ mAP@0.5: {float(val_results.box.map50):.4f}\")\n",
    "print(f\"  ‚Ä¢ mAP@0.5:0.95: {float(val_results.box.map):.4f}\")\n",
    "print(f\"  ‚Ä¢ Precision: {float(val_results.box.mp):.4f}\")\n",
    "print(f\"  ‚Ä¢ Recall: {float(val_results.box.mr):.4f}\")\n",
    "print(f\"\\nüíæ All outputs saved to: {config.OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
